{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ffd69a",
   "metadata": {},
   "source": [
    "# Défi quotidien : classer les chiffres manuscrits avec les CNN\n",
    "\n",
    "\n",
    "## 👩‍🏫 👩🏿‍🏫 Ce que vous apprendrez\n",
    "Comment charger et prétraiter l'ensemble de données MNIST.\n",
    "Comment construire un réseau neuronal entièrement connecté de base pour la classification d'images.\n",
    "Comment construire et former un réseau neuronal convolutif (CNN) pour la classification d'images.\n",
    "Comprendre l’impact des différentes architectures réseau sur les performances.\n",
    "Fonctionnalités de base de Keras pour la création et la formation de modèles.\n",
    "\n",
    "\n",
    "## 🛠️ Ce que vous allez créer\n",
    "Vous allez créer deux modèles :\n",
    "\n",
    "Un réseau neuronal entièrement connecté (couches denses) pour classer les chiffres manuscrits de l'ensemble de données MNIST.\n",
    "Un réseau neuronal convolutif (CNN) pour classer les chiffres manuscrits de l'ensemble de données MNIST et comparer ses performances avec le premier modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a953edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agathelebescond/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (60000, 28, 28)\n",
      "y_train.shape : (60000,)\n",
      "x_test.shape  : (10000, 28, 28)\n",
      "y_test.shape  : (10000,)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. CHARGER L'ENSEMBLE DE DONNÉES MNIST\n",
    "# ================================\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Chargement des données\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Affichage des dimensions\n",
    "print(\"x_train.shape :\", x_train.shape)  # (60000, 28, 28)\n",
    "print(\"y_train.shape :\", y_train.shape)  # (60000,)\n",
    "print(\"x_test.shape  :\", x_test.shape)   # (10000, 28, 28)\n",
    "print(\"y_test.shape  :\", y_test.shape)   # (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec3f3c5",
   "metadata": {},
   "source": [
    "###  **Analyse des dimensions :**\n",
    "\n",
    "```python\n",
    "x_train.shape : (60000, 28, 28)\n",
    "y_train.shape : (60000,)\n",
    "x_test.shape  : (10000, 28, 28)\n",
    "y_test.shape  : (10000,)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  **Interprétation :**\n",
    "\n",
    "####  **x\\_train : (60000, 28, 28)**\n",
    "\n",
    "* Il y a **60 000 images d'entraînement**.\n",
    "* Chaque image est en niveaux de gris (1 canal) et mesure **28 pixels par 28 pixels**.\n",
    "\n",
    "####  **y\\_train : (60000,)**\n",
    "\n",
    "* Il y a **60 000 étiquettes associées** (entre 0 et 9) correspondant à chaque image de `x_train`.\n",
    "\n",
    "####  **x\\_test : (10000, 28, 28)**\n",
    "\n",
    "* Il y a **10 000 images de test** avec la même structure que les données d'entraînement.\n",
    "\n",
    "####  **y\\_test : (10000,)**\n",
    "\n",
    "* 10 000 étiquettes pour évaluer la performance du modèle.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Conclusion :**\n",
    "\n",
    "* L’ensemble MNIST contient **70 000 chiffres manuscrits** (60k pour entraînement, 10k pour test).\n",
    "* Chaque image est une **matrice 2D** de 28x28 pixels à **1 canal (niveau de gris)**.\n",
    "* Les étiquettes sont **des entiers de 0 à 9** représentant le chiffre dessiné.\n",
    "* Les formats sont **compatibles avec les modèles denses et CNN après le prétraitement.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0013c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. PRÉTRAITER LES DONNÉES POUR RÉSEAU NEURONAL ENTIÈREMENT CONNECTÉ\n",
    "# ================================\n",
    "# Aplatir les images 28x28 en vecteurs de 784\n",
    "x_train_flat = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
    "x_test_flat = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
    "\n",
    "# Encodage one-hot des étiquettes\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb6fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entraînement modèle Dense ===\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agathelebescond/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.4435 - val_accuracy: 0.9665 - val_loss: 0.1170\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.1159 - val_accuracy: 0.9735 - val_loss: 0.0908\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9760 - loss: 0.0738 - val_accuracy: 0.9758 - val_loss: 0.0825\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0531 - val_accuracy: 0.9772 - val_loss: 0.0801\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9867 - loss: 0.0419 - val_accuracy: 0.9747 - val_loss: 0.0955\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9691 - loss: 0.1112\n",
      "Précision du modèle Dense : 0.9722999930381775\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. CONSTRUIRE ET ENTRAÎNER LE RÉSEAU NEURONAL ENTIÈREMENT CONNECTÉ\n",
    "# ================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Création du modèle dense\n",
    "model_dense = Sequential()\n",
    "model_dense.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_dense.add(Dense(64, activation='relu'))\n",
    "model_dense.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model_dense.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Entraînement\n",
    "print(\"\\n=== Entraînement modèle Dense ===\")\n",
    "model_dense.fit(x_train_flat, y_train_cat, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Évaluation\n",
    "loss_dense, acc_dense = model_dense.evaluate(x_test_flat, y_test_cat)\n",
    "print(\"Précision du modèle Dense :\", acc_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bb41b",
   "metadata": {},
   "source": [
    "####  **Évolution de l’apprentissage sur 5 époques :**\n",
    "\n",
    "| Époque | Précision entraînement | Perte entraînement | Précision validation | Perte validation |\n",
    "| ------ | ---------------------- | ------------------ | -------------------- | ---------------- |\n",
    "| 1      | 87.18 %                | 0.4445             | 96.60 %              | 0.1205           |\n",
    "| 2      | 96.52 %                | 0.1143             | 97.42 %              | 0.0949           |\n",
    "| 3      | 97.70 %                | 0.0740             | 97.67 %              | 0.0829           |\n",
    "| 4      | 98.18 %                | 0.0583             | 97.67 %              | 0.0750           |\n",
    "| 5      | 98.64 %                | 0.0419             | 98.05 %              | 0.0720           |\n",
    "\n",
    "---\n",
    "\n",
    "####  **Évaluation finale sur le jeu de test :**\n",
    "\n",
    "* **Précision test : 97.66 %**\n",
    "* **Perte test : 0.0951**\n",
    "\n",
    "---\n",
    "\n",
    "###  **Interprétation**\n",
    "\n",
    "* Le modèle **apprend efficacement** : la précision augmente et la perte diminue régulièrement.\n",
    "* Il **généralise bien** : la précision sur le jeu de validation reste élevée et stable.\n",
    "* **Pas de surapprentissage apparent** en 5 époques (écart train/val faible).\n",
    "* Le modèle atteint une **excellente précision** pour un modèle dense simple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e415be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. PRÉTRAITER LES DONNÉES POUR CNN\n",
    "# ================================\n",
    "# Ajouter une dimension canal : (60000, 28, 28, 1)\n",
    "x_train_cnn = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "x_test_cnn = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "\n",
    "# Réutilisation des étiquettes one-hot déjà créées : y_train_cat, y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65975ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entraînement modèle CNN ===\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agathelebescond/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9017 - loss: 0.3218 - val_accuracy: 0.9858 - val_loss: 0.0534\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0507 - val_accuracy: 0.9877 - val_loss: 0.0397\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0329 - val_accuracy: 0.9897 - val_loss: 0.0355\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0190 - val_accuracy: 0.9895 - val_loss: 0.0414\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.9912 - val_loss: 0.0301\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0423\n",
      "Précision du modèle CNN : 0.9890999794006348\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. CONSTRUIRE ET ENTRAÎNER LE RÉSEAU CONVOLUTIF\n",
    "# ================================\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Création du modèle CNN\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Entraînement\n",
    "print(\"\\n=== Entraînement modèle CNN ===\")\n",
    "model_cnn.fit(x_train_cnn, y_train_cat, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Évaluation\n",
    "loss_cnn, acc_cnn = model_cnn.evaluate(x_test_cnn, y_test_cat)\n",
    "print(\"Précision du modèle CNN :\", acc_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1095ae14",
   "metadata": {},
   "source": [
    "#### Résumé de l’apprentissage :\n",
    "\n",
    "| Époque | Précision entraînement | Perte entraînement | Précision validation | Perte validation |\n",
    "| ------ | ---------------------- | ------------------ | -------------------- | ---------------- |\n",
    "| 1      | 89.34 %                | 0.3306             | 98.77 %              | 0.0475           |\n",
    "| 2      | 98.74 %                | 0.0424             | 98.88 %              | 0.0361           |\n",
    "| 3      | 99.08 %                | 0.0279             | 98.88 %              | 0.0395           |\n",
    "| 4      | 99.25 %                | 0.0218             | 99.25 %              | 0.0316           |\n",
    "| 5      | 99.53 %                | 0.0148             | 99.05 %              | 0.0372           |\n",
    "\n",
    "---\n",
    "\n",
    "#### Résultat final sur le jeu de test :\n",
    "\n",
    "* **Précision test : 99.10 %**\n",
    "* **Perte test : 0.0337**\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation :\n",
    "\n",
    "* Le CNN **atteint une meilleure performance** que le modèle dense.\n",
    "* La **courbe d’apprentissage est rapide** dès la 1re époque.\n",
    "* La **précision de validation est très stable** autour de 99 %, ce qui montre une bonne généralisation.\n",
    "* **Pas de surapprentissage** en 5 époques.\n",
    "* Il capture mieux les **caractéristiques spatiales** des chiffres manuscrits (bords, formes), ce que le modèle dense ne fait pas.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion comparative :\n",
    "\n",
    "| Critère        | Modèle Dense | Modèle CNN              |\n",
    "| -------------- | ------------ | ----------------------- |\n",
    "| Précision test | 97.66 %      | 99.10 %                 |\n",
    "| Perte test     | 0.0951       | 0.0337                  |\n",
    "| Convergence    | Bonne        | Meilleure               |\n",
    "| Généralisation | Bonne        | Excellente              |\n",
    "| Architecture   | Simple       | Plus adaptée aux images |\n",
    "\n",
    "Le **CNN est nettement plus performant** pour ce type de données (images 2D).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11865989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparaison des performances ===\n",
      "Modèle Dense - précision : 0.9723\n",
      "Modèle CNN   - précision : 0.9891\n",
      "Le CNN est plus performant que le modèle dense.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 6. COMPARAISON DES PERFORMANCES\n",
    "# ================================\n",
    "print(\"\\n=== Comparaison des performances ===\")\n",
    "print(f\"Modèle Dense - précision : {acc_dense:.4f}\")\n",
    "print(f\"Modèle CNN   - précision : {acc_cnn:.4f}\")\n",
    "\n",
    "if acc_cnn > acc_dense:\n",
    "    print(\"Le CNN est plus performant que le modèle dense.\")\n",
    "else:\n",
    "    print(\"Le modèle dense est plus performant que le CNN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a7c6e",
   "metadata": {},
   "source": [
    "#### Résultats :\n",
    "\n",
    "* **Modèle Dense - précision test :** 97.66 %\n",
    "* **Modèle CNN   - précision test :** 99.10 %\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation :\n",
    "\n",
    "* Le **CNN surpasse clairement** le modèle dense en précision.\n",
    "* L'écart (\\~1.44 points) est **significatif** à ce niveau de performance.\n",
    "* Le CNN **exploite la structure spatiale** des images via les convolutions, contrairement au modèle dense qui traite les pixels de manière indépendante.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion :\n",
    "\n",
    "> **Le CNN est plus performant que le modèle dense** pour la classification d’images MNIST. Il est donc **plus adapté** à ce type de tâche.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
