{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ffd69a",
   "metadata": {},
   "source": [
    "# D√©fi quotidien : classer les chiffres manuscrits avec les CNN\n",
    "\n",
    "\n",
    "## üë©‚Äçüè´ üë©üèø‚Äçüè´ Ce que vous apprendrez\n",
    "Comment charger et pr√©traiter l'ensemble de donn√©es MNIST.\n",
    "Comment construire un r√©seau neuronal enti√®rement connect√© de base pour la classification d'images.\n",
    "Comment construire et former un r√©seau neuronal convolutif (CNN) pour la classification d'images.\n",
    "Comprendre l‚Äôimpact des diff√©rentes architectures r√©seau sur les performances.\n",
    "Fonctionnalit√©s de base de Keras pour la cr√©ation et la formation de mod√®les.\n",
    "\n",
    "\n",
    "## üõ†Ô∏è Ce que vous allez cr√©er\n",
    "Vous allez cr√©er deux mod√®les :\n",
    "\n",
    "Un r√©seau neuronal enti√®rement connect√© (couches denses) pour classer les chiffres manuscrits de l'ensemble de donn√©es MNIST.\n",
    "Un r√©seau neuronal convolutif (CNN) pour classer les chiffres manuscrits de l'ensemble de donn√©es MNIST et comparer ses performances avec le premier mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a953edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agathelebescond/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (60000, 28, 28)\n",
      "y_train.shape : (60000,)\n",
      "x_test.shape  : (10000, 28, 28)\n",
      "y_test.shape  : (10000,)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. CHARGER L'ENSEMBLE DE DONN√âES MNIST\n",
    "# ================================\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Chargement des donn√©es\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Affichage des dimensions\n",
    "print(\"x_train.shape :\", x_train.shape)  # (60000, 28, 28)\n",
    "print(\"y_train.shape :\", y_train.shape)  # (60000,)\n",
    "print(\"x_test.shape  :\", x_test.shape)   # (10000, 28, 28)\n",
    "print(\"y_test.shape  :\", y_test.shape)   # (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec3f3c5",
   "metadata": {},
   "source": [
    "###  **Analyse des dimensions :**\n",
    "\n",
    "```python\n",
    "x_train.shape : (60000, 28, 28)\n",
    "y_train.shape : (60000,)\n",
    "x_test.shape  : (10000, 28, 28)\n",
    "y_test.shape  : (10000,)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  **Interpr√©tation :**\n",
    "\n",
    "####  **x\\_train : (60000, 28, 28)**\n",
    "\n",
    "* Il y a **60 000 images d'entra√Ænement**.\n",
    "* Chaque image est en niveaux de gris (1 canal) et mesure **28 pixels par 28 pixels**.\n",
    "\n",
    "####  **y\\_train : (60000,)**\n",
    "\n",
    "* Il y a **60 000 √©tiquettes associ√©es** (entre 0 et 9) correspondant √† chaque image de `x_train`.\n",
    "\n",
    "####  **x\\_test : (10000, 28, 28)**\n",
    "\n",
    "* Il y a **10 000 images de test** avec la m√™me structure que les donn√©es d'entra√Ænement.\n",
    "\n",
    "####  **y\\_test : (10000,)**\n",
    "\n",
    "* 10 000 √©tiquettes pour √©valuer la performance du mod√®le.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Conclusion :**\n",
    "\n",
    "* L‚Äôensemble MNIST contient **70 000 chiffres manuscrits** (60k pour entra√Ænement, 10k pour test).\n",
    "* Chaque image est une **matrice 2D** de 28x28 pixels √† **1 canal (niveau de gris)**.\n",
    "* Les √©tiquettes sont **des entiers de 0 √† 9** repr√©sentant le chiffre dessin√©.\n",
    "* Les formats sont **compatibles avec les mod√®les denses et CNN apr√®s le pr√©traitement.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0013c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. PR√âTRAITER LES DONN√âES POUR R√âSEAU NEURONAL ENTI√àREMENT CONNECT√â\n",
    "# ================================\n",
    "# Aplatir les images 28x28 en vecteurs de 784\n",
    "x_train_flat = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
    "x_test_flat = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
    "\n",
    "# Encodage one-hot des √©tiquettes\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb6fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entra√Ænement mod√®le Dense ===\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agathelebescond/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.4435 - val_accuracy: 0.9665 - val_loss: 0.1170\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.1159 - val_accuracy: 0.9735 - val_loss: 0.0908\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9760 - loss: 0.0738 - val_accuracy: 0.9758 - val_loss: 0.0825\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0531 - val_accuracy: 0.9772 - val_loss: 0.0801\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9867 - loss: 0.0419 - val_accuracy: 0.9747 - val_loss: 0.0955\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9691 - loss: 0.1112\n",
      "Pr√©cision du mod√®le Dense : 0.9722999930381775\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. CONSTRUIRE ET ENTRA√éNER LE R√âSEAU NEURONAL ENTI√àREMENT CONNECT√â\n",
    "# ================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Cr√©ation du mod√®le dense\n",
    "model_dense = Sequential()\n",
    "model_dense.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_dense.add(Dense(64, activation='relu'))\n",
    "model_dense.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilation du mod√®le\n",
    "model_dense.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Entra√Ænement\n",
    "print(\"\\n=== Entra√Ænement mod√®le Dense ===\")\n",
    "model_dense.fit(x_train_flat, y_train_cat, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# √âvaluation\n",
    "loss_dense, acc_dense = model_dense.evaluate(x_test_flat, y_test_cat)\n",
    "print(\"Pr√©cision du mod√®le Dense :\", acc_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bb41b",
   "metadata": {},
   "source": [
    "####  **√âvolution de l‚Äôapprentissage sur 5 √©poques :**\n",
    "\n",
    "| √âpoque | Pr√©cision entra√Ænement | Perte entra√Ænement | Pr√©cision validation | Perte validation |\n",
    "| ------ | ---------------------- | ------------------ | -------------------- | ---------------- |\n",
    "| 1      | 87.18 %                | 0.4445             | 96.60 %              | 0.1205           |\n",
    "| 2      | 96.52 %                | 0.1143             | 97.42 %              | 0.0949           |\n",
    "| 3      | 97.70 %                | 0.0740             | 97.67 %              | 0.0829           |\n",
    "| 4      | 98.18 %                | 0.0583             | 97.67 %              | 0.0750           |\n",
    "| 5      | 98.64 %                | 0.0419             | 98.05 %              | 0.0720           |\n",
    "\n",
    "---\n",
    "\n",
    "####  **√âvaluation finale sur le jeu de test :**\n",
    "\n",
    "* **Pr√©cision test : 97.66 %**\n",
    "* **Perte test : 0.0951**\n",
    "\n",
    "---\n",
    "\n",
    "###  **Interpr√©tation**\n",
    "\n",
    "* Le mod√®le **apprend efficacement** : la pr√©cision augmente et la perte diminue r√©guli√®rement.\n",
    "* Il **g√©n√©ralise bien** : la pr√©cision sur le jeu de validation reste √©lev√©e et stable.\n",
    "* **Pas de surapprentissage apparent** en 5 √©poques (√©cart train/val faible).\n",
    "* Le mod√®le atteint une **excellente pr√©cision** pour un mod√®le dense simple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e415be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. PR√âTRAITER LES DONN√âES POUR CNN\n",
    "# ================================\n",
    "# Ajouter une dimension canal : (60000, 28, 28, 1)\n",
    "x_train_cnn = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "x_test_cnn = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "\n",
    "# R√©utilisation des √©tiquettes one-hot d√©j√† cr√©√©es : y_train_cat, y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65975ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entra√Ænement mod√®le CNN ===\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agathelebescond/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9017 - loss: 0.3218 - val_accuracy: 0.9858 - val_loss: 0.0534\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0507 - val_accuracy: 0.9877 - val_loss: 0.0397\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0329 - val_accuracy: 0.9897 - val_loss: 0.0355\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0190 - val_accuracy: 0.9895 - val_loss: 0.0414\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.9912 - val_loss: 0.0301\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0423\n",
      "Pr√©cision du mod√®le CNN : 0.9890999794006348\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. CONSTRUIRE ET ENTRA√éNER LE R√âSEAU CONVOLUTIF\n",
    "# ================================\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Cr√©ation du mod√®le CNN\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Entra√Ænement\n",
    "print(\"\\n=== Entra√Ænement mod√®le CNN ===\")\n",
    "model_cnn.fit(x_train_cnn, y_train_cat, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# √âvaluation\n",
    "loss_cnn, acc_cnn = model_cnn.evaluate(x_test_cnn, y_test_cat)\n",
    "print(\"Pr√©cision du mod√®le CNN :\", acc_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1095ae14",
   "metadata": {},
   "source": [
    "#### R√©sum√© de l‚Äôapprentissage :\n",
    "\n",
    "| √âpoque | Pr√©cision entra√Ænement | Perte entra√Ænement | Pr√©cision validation | Perte validation |\n",
    "| ------ | ---------------------- | ------------------ | -------------------- | ---------------- |\n",
    "| 1      | 89.34 %                | 0.3306             | 98.77 %              | 0.0475           |\n",
    "| 2      | 98.74 %                | 0.0424             | 98.88 %              | 0.0361           |\n",
    "| 3      | 99.08 %                | 0.0279             | 98.88 %              | 0.0395           |\n",
    "| 4      | 99.25 %                | 0.0218             | 99.25 %              | 0.0316           |\n",
    "| 5      | 99.53 %                | 0.0148             | 99.05 %              | 0.0372           |\n",
    "\n",
    "---\n",
    "\n",
    "#### R√©sultat final sur le jeu de test :\n",
    "\n",
    "* **Pr√©cision test : 99.10 %**\n",
    "* **Perte test : 0.0337**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpr√©tation :\n",
    "\n",
    "* Le CNN **atteint une meilleure performance** que le mod√®le dense.\n",
    "* La **courbe d‚Äôapprentissage est rapide** d√®s la 1re √©poque.\n",
    "* La **pr√©cision de validation est tr√®s stable** autour de 99 %, ce qui montre une bonne g√©n√©ralisation.\n",
    "* **Pas de surapprentissage** en 5 √©poques.\n",
    "* Il capture mieux les **caract√©ristiques spatiales** des chiffres manuscrits (bords, formes), ce que le mod√®le dense ne fait pas.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion comparative :\n",
    "\n",
    "| Crit√®re        | Mod√®le Dense | Mod√®le CNN              |\n",
    "| -------------- | ------------ | ----------------------- |\n",
    "| Pr√©cision test | 97.66 %      | 99.10 %                 |\n",
    "| Perte test     | 0.0951       | 0.0337                  |\n",
    "| Convergence    | Bonne        | Meilleure               |\n",
    "| G√©n√©ralisation | Bonne        | Excellente              |\n",
    "| Architecture   | Simple       | Plus adapt√©e aux images |\n",
    "\n",
    "Le **CNN est nettement plus performant** pour ce type de donn√©es (images 2D).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11865989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparaison des performances ===\n",
      "Mod√®le Dense - pr√©cision : 0.9723\n",
      "Mod√®le CNN   - pr√©cision : 0.9891\n",
      "Le CNN est plus performant que le mod√®le dense.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 6. COMPARAISON DES PERFORMANCES\n",
    "# ================================\n",
    "print(\"\\n=== Comparaison des performances ===\")\n",
    "print(f\"Mod√®le Dense - pr√©cision : {acc_dense:.4f}\")\n",
    "print(f\"Mod√®le CNN   - pr√©cision : {acc_cnn:.4f}\")\n",
    "\n",
    "if acc_cnn > acc_dense:\n",
    "    print(\"Le CNN est plus performant que le mod√®le dense.\")\n",
    "else:\n",
    "    print(\"Le mod√®le dense est plus performant que le CNN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a7c6e",
   "metadata": {},
   "source": [
    "#### R√©sultats :\n",
    "\n",
    "* **Mod√®le Dense - pr√©cision test :** 97.66‚ÄØ%\n",
    "* **Mod√®le CNN   - pr√©cision test :** 99.10‚ÄØ%\n",
    "\n",
    "---\n",
    "\n",
    "### Interpr√©tation :\n",
    "\n",
    "* Le **CNN surpasse clairement** le mod√®le dense en pr√©cision.\n",
    "* L'√©cart (\\~1.44 points) est **significatif** √† ce niveau de performance.\n",
    "* Le CNN **exploite la structure spatiale** des images via les convolutions, contrairement au mod√®le dense qui traite les pixels de mani√®re ind√©pendante.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion :\n",
    "\n",
    "> **Le CNN est plus performant que le mod√®le dense** pour la classification d‚Äôimages MNIST. Il est donc **plus adapt√©** √† ce type de t√¢che.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
