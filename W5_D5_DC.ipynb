{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJdGLXrkMvwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Daily Challenge\n",
        "\n",
        "1. Preprocess the Data:\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "Mounted at /content/drive\n",
        "\n",
        "# Importations nÃ©cessaires\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# 2. DÃ©finir les chemins\n",
        "drive_zip_path = '/content/drive/MyDrive/Colab Notebooks/W5/D5/Dogs vs Cats.zip'  # Chemin dans Drive\n",
        "extract_path = '/content/cats_and_dogs'\n",
        "original_train_dir = os.path.join(extract_path, 'train/train')  # AdaptÃ© Ã  la structure rÃ©elle\n",
        "processed_train_dir = os.path.join(extract_path, 'processed_train')\n",
        "validation_dir = os.path.join(extract_path, 'validation')\n",
        "# 3. Nettoyage initial et crÃ©ation des dossiers\n",
        "!rm -rf {extract_path}  # Suppression complÃ¨te avant extraction\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "# 4. Copie depuis Drive vers Colab\n",
        "!cp \"{drive_zip_path}\" \"{extract_path}/Dogs_vs_Cats.zip\"\n",
        "# 5. Extraction\n",
        "with zipfile.ZipFile(os.path.join(extract_path, 'Dogs_vs_Cats.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "# 6. VÃ©rification de la structure\n",
        "print(\"Structure aprÃ¨s extraction:\")\n",
        "!find {extract_path} -type d | sort\n",
        "print(\"\\nContenu du dossier train/train:\")\n",
        "!ls -la {original_train_dir} | head -10\n",
        "# 7. Fonction pour organiser les fichiers\n",
        "def organize_images(source_dir, train_dest, val_dest, test_size=0.2):\n",
        "    \"\"\"Organise les images en train/validation avec sÃ©paration par classe\"\"\"\n",
        "    os.makedirs(train_dest, exist_ok=True)\n",
        "    os.makedirs(val_dest, exist_ok=True)\n",
        "    # CrÃ©er sous-dossiers cats/dogs\n",
        "    for folder in [train_dest, val_dest]:\n",
        "        for class_name in ['cats', 'dogs']:\n",
        "            os.makedirs(os.path.join(folder, class_name), exist_ok=True)\n",
        "    # Lister les fichiers images\n",
        "    all_files = [f for f in os.listdir(source_dir)\n",
        "                if os.path.isfile(os.path.join(source_dir, f))\n",
        "                and f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    if not all_files:\n",
        "        raise ValueError(f\"Aucune image trouvÃ©e dans {source_dir}\")\n",
        "    # SÃ©paration train/validation\n",
        "    train_files, val_files = train_test_split(all_files, test_size=test_size, random_state=42)\n",
        "    # DÃ©placement des fichiers\n",
        "    for file_list, dest in [(train_files, train_dest), (val_files, val_dest)]:\n",
        "        for file in file_list:\n",
        "            src = os.path.join(source_dir, file)\n",
        "            class_folder = 'cats' if 'cat' in file.lower() else 'dogs'\n",
        "            dst = os.path.join(dest, class_folder, file)\n",
        "            shutil.move(src, dst)\n",
        "# 8. Organiser les images\n",
        "organize_images(\n",
        "    source_dir=original_train_dir,\n",
        "    train_dest=processed_train_dir,\n",
        "    val_dest=validation_dir,\n",
        "    test_size=0.2\n",
        ")\n",
        "# 9. VÃ©rification aprÃ¨s organisation\n",
        "print(\"\\nStructure aprÃ¨s organisation:\")\n",
        "!find {extract_path} -type d | sort\n",
        "print(\"\\nContenu de processed_train:\")\n",
        "!ls -la {processed_train_dir} | head -10\n",
        "print(\"\\nContenu de validation:\")\n",
        "!ls -la {validation_dir} | head -10\n",
        "# 10. ParamÃ¨tres des images\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "# 11. Augmentation des donnÃ©es\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# 12. CrÃ©ation des gÃ©nÃ©rateurs\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    processed_train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "# 13. Affichage des informations\n",
        "print(\"\\nClasses d'entraÃ®nement:\", train_generator.class_indices)\n",
        "print(\"Nombre d'images d'entraÃ®nement:\", train_generator.samples)\n",
        "print(\"Nombre d'images de validation:\", validation_generator.samples)\n",
        "\n",
        "Structure aprÃ¨s extraction:\n",
        "/content/cats_and_dogs\n",
        "/content/cats_and_dogs/test\n",
        "/content/cats_and_dogs/test/test\n",
        "/content/cats_and_dogs/train\n",
        "/content/cats_and_dogs/train/train\n",
        "\n",
        "Contenu du dossier train/train:\n",
        "total 609272\n",
        "drwxr-xr-x 2 root root 778240 Jul 11 14:07 .\n",
        "drwxr-xr-x 3 root root   4096 Jul 11 14:07 ..\n",
        "-rw-r--r-- 1 root root  12414 Jul 11 14:07 cat.0.jpg\n",
        "-rw-r--r-- 1 root root  21944 Jul 11 14:07 cat.10000.jpg\n",
        "-rw-r--r-- 1 root root  27322 Jul 11 14:07 cat.10001.jpg\n",
        "-rw-r--r-- 1 root root  25723 Jul 11 14:07 cat.10002.jpg\n",
        "-rw-r--r-- 1 root root  28035 Jul 11 14:07 cat.10003.jpg\n",
        "-rw-r--r-- 1 root root  12973 Jul 11 14:07 cat.10004.jpg\n",
        "-rw-r--r-- 1 root root   8245 Jul 11 14:07 cat.10005.jpg\n",
        "\n",
        "Structure aprÃ¨s organisation:\n",
        "/content/cats_and_dogs\n",
        "/content/cats_and_dogs/processed_train\n",
        "/content/cats_and_dogs/processed_train/cats\n",
        "/content/cats_and_dogs/processed_train/dogs\n",
        "/content/cats_and_dogs/test\n",
        "/content/cats_and_dogs/test/test\n",
        "/content/cats_and_dogs/train\n",
        "/content/cats_and_dogs/train/train\n",
        "/content/cats_and_dogs/validation\n",
        "/content/cats_and_dogs/validation/cats\n",
        "/content/cats_and_dogs/validation/dogs\n",
        "\n",
        "Contenu de processed_train:\n",
        "total 572\n",
        "drwxr-xr-x 4 root root   4096 Jul 11 14:07 .\n",
        "drwxr-xr-x 6 root root   4096 Jul 11 14:07 ..\n",
        "drwxr-xr-x 2 root root 286720 Jul 11 14:07 cats\n",
        "drwxr-xr-x 2 root root 282624 Jul 11 14:07 dogs\n",
        "\n",
        "Contenu de validation:\n",
        "total 152\n",
        "drwxr-xr-x 4 root root  4096 Jul 11 14:07 .\n",
        "drwxr-xr-x 6 root root  4096 Jul 11 14:07 ..\n",
        "drwxr-xr-x 2 root root 69632 Jul 11 14:07 cats\n",
        "drwxr-xr-x 2 root root 69632 Jul 11 14:07 dogs\n",
        "Found 20000 images belonging to 2 classes.\n",
        "Found 5000 images belonging to 2 classes.\n",
        "\n",
        "Classes d'entraÃ®nement: {'cats': 0, 'dogs': 1}\n",
        "Nombre d'images d'entraÃ®nement: 20000\n",
        "Nombre d'images de validation: 5000\n",
        "2. Build the Model:\n",
        "\n",
        "Le script ci-dessous est un CNN avec trois couches convolutionnelles, chacune suivie d'un max-pooling, puis une couche de flatten, une couche fully connectÃ©e avec Dropout, et enfin la couche de sortie adaptÃ©e Ã  la classification binaire. La compilation utilise l'optimiseur Adam et la fonction de perte binaire croisÃ©e, ce qui est standard pour ce type de problÃ¨me.\n",
        "\n",
        "\n",
        "# Importation des modules nÃ©cessaires\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# DÃ©finition des dimensions des images (selon ton script initial)\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "# 2. Construction du modÃ¨le CNN\n",
        "model = Sequential()\n",
        "\n",
        "# PremiÃ¨re couche convolutionnelle avec ReLU et max-pooling\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# DeuxiÃ¨me couche convolutionnelle\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# TroisiÃ¨me couche convolutionnelle\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten pour transformer la sortie en vecteur\n",
        "model.add(Flatten())\n",
        "\n",
        "# Couche fully connectÃ©e avec 512 unitÃ©s et ReLU\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Dropout pour rÃ©duire le surapprentissage\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Couche de sortie avec sigmoid pour la classification binaire\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilation du modÃ¨le avec Adam et binary cross-entropy\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Affichage de la structure du modÃ¨le\n",
        "model.summary()\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
        "Model: \"sequential\"\n",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
        "â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ\n",
        "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
        "â”‚ conv2d (Conv2D)                 â”‚ (None, 148, 148, 32)   â”‚           896 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ max_pooling2d (MaxPooling2D)    â”‚ (None, 74, 74, 32)     â”‚             0 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ conv2d_1 (Conv2D)               â”‚ (None, 72, 72, 64)     â”‚        18,496 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ max_pooling2d_1 (MaxPooling2D)  â”‚ (None, 36, 36, 64)     â”‚             0 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ conv2d_2 (Conv2D)               â”‚ (None, 34, 34, 128)    â”‚        73,856 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ max_pooling2d_2 (MaxPooling2D)  â”‚ (None, 17, 17, 128)    â”‚             0 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ flatten (Flatten)               â”‚ (None, 36992)          â”‚             0 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ dense (Dense)                   â”‚ (None, 512)            â”‚    18,940,416 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ dropout (Dropout)               â”‚ (None, 512)            â”‚             0 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ dense_1 (Dense)                 â”‚ (None, 1)              â”‚           513 â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        " Total params: 19,034,177 (72.61 MB)\n",
        " Trainable params: 19,034,177 (72.61 MB)\n",
        " Non-trainable params: 0 (0.00 B)\n",
        "3. Train the Model:\n",
        "\n",
        "\n",
        "# EntraÃ®ner le modÃ¨le pendant 15 Ã©poques\n",
        "history = model.fit(\n",
        "    train_generator,              # GÃ©nÃ©rateur de donnÃ©es d'entraÃ®nement avec augmentation\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,  # Nombre de pas par Ã©poque\n",
        "    epochs=EPOCHS,                # Nombre total d'Ã©poques d'entraÃ®nement\n",
        "    validation_data=validation_generator,  # DonnÃ©es de validation pour Ã©valuer les performances\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,  # Nombre de pas de validation par Ã©poque\n",
        "    verbose=1                     # Affiche la progression pendant l'entraÃ®nement\n",
        ")\n",
        "\n",
        "# Affichage des performances d'entraÃ®nement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fonctions auxiliaires pour visualiser l'exactitude et la perte\n",
        "def plot_training_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(EPOCHS)\n",
        "\n",
        "    # Tracer la courbe d'exactitude\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Exactitude entraÃ®nement')\n",
        "    plt.plot(epochs_range, val_acc, label='Exactitude validation')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Exactitude au fil des Ã©poques')\n",
        "\n",
        "    # Tracer la courbe de perte\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Perte entraÃ®nement')\n",
        "    plt.plot(epochs_range, val_loss, label='Perte validation')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Perte au fil des Ã©poques')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualiser les courbes\n",
        "plot_training_history(history)\n",
        "\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
        "  self._warn_if_super_not_called()\n",
        "Epoch 1/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 148s 226ms/step - accuracy: 0.5524 - loss: 0.6840 - val_accuracy: 0.6186 - val_loss: 0.6358\n",
        "Epoch 2/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 193s 220ms/step - accuracy: 0.6133 - loss: 0.6497 - val_accuracy: 0.7194 - val_loss: 0.5681\n",
        "Epoch 3/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 141s 218ms/step - accuracy: 0.6756 - loss: 0.5992 - val_accuracy: 0.7286 - val_loss: 0.5331\n",
        "Epoch 4/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 138s 221ms/step - accuracy: 0.7069 - loss: 0.5698 - val_accuracy: 0.7432 - val_loss: 0.5107\n",
        "Epoch 5/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 138s 220ms/step - accuracy: 0.7130 - loss: 0.5575 - val_accuracy: 0.7628 - val_loss: 0.4931\n",
        "Epoch 6/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 138s 221ms/step - accuracy: 0.7250 - loss: 0.5426 - val_accuracy: 0.7778 - val_loss: 0.4704\n",
        "Epoch 7/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 140s 218ms/step - accuracy: 0.7382 - loss: 0.5254 - val_accuracy: 0.7770 - val_loss: 0.4733\n",
        "Epoch 8/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 137s 219ms/step - accuracy: 0.7458 - loss: 0.5059 - val_accuracy: 0.8019 - val_loss: 0.4321\n",
        "Epoch 9/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 141s 218ms/step - accuracy: 0.7621 - loss: 0.4911 - val_accuracy: 0.7792 - val_loss: 0.4594\n",
        "Epoch 10/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 142s 218ms/step - accuracy: 0.7795 - loss: 0.4705 - val_accuracy: 0.8093 - val_loss: 0.4295\n",
        "Epoch 11/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 136s 217ms/step - accuracy: 0.7875 - loss: 0.4502 - val_accuracy: 0.8161 - val_loss: 0.4060\n",
        "Epoch 12/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 203s 315ms/step - accuracy: 0.7870 - loss: 0.4508 - val_accuracy: 0.8249 - val_loss: 0.3974\n",
        "Epoch 13/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 202s 315ms/step - accuracy: 0.7900 - loss: 0.4452 - val_accuracy: 0.8313 - val_loss: 0.3885\n",
        "Epoch 14/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 136s 218ms/step - accuracy: 0.8021 - loss: 0.4272 - val_accuracy: 0.8267 - val_loss: 0.3861\n",
        "Epoch 15/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 142s 218ms/step - accuracy: 0.8054 - loss: 0.4235 - val_accuracy: 0.8393 - val_loss: 0.3657\n",
        "\n",
        "ğŸ” Lecture des courbes\n",
        "\n",
        "Exactitude au fil des Ã©poques (gauche)\n",
        "ğŸ”µ EntraÃ®nement : progression rÃ©guliÃ¨re jusquâ€™Ã  ~0.80, ce qui montre que le modÃ¨le apprend de faÃ§on constante.\n",
        "\n",
        "ğŸŸ  Validation : dÃ©marre autour de 0.60 et atteint ~0.83, parfois plus Ã©levÃ©e que lâ€™entraÃ®nement â€” ce qui peut indiquer une bonne gÃ©nÃ©ralisation ou des effets de rÃ©gularisation.\n",
        "\n",
        "Perte au fil des Ã©poques (droite)\n",
        "ğŸ”µ EntraÃ®nement : la perte diminue progressivement vers ~0.40, ce qui confirme lâ€™apprentissage.\n",
        "\n",
        "ğŸŸ  Validation : perte en baisse rapide au dÃ©part, puis fluctue lÃ©gÃ¨rement, terminant autour de ~0.35 â€” ce qui est trÃ¨s bon.\n",
        "\n",
        "ğŸ§  Ce que Ã§a rÃ©vÃ¨le :\n",
        "\n",
        "image.png\n",
        "\n",
        "5. Bonus:\n",
        "\n",
        "\n",
        "# ğŸ“‚ 1. DÃ©finir les chemins (Ã  adapter si nÃ©cessaire)\n",
        "train_dir = '/content/cats_and_dogs/processed_train'\n",
        "validation_dir = '/content/cats_and_dogs/validation'\n",
        "\n",
        "# âš™ï¸ 2. ParamÃ¨tres de traitement\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "batch_size = 32\n",
        "EPOCHS = 15\n",
        "\n",
        "# ğŸ§° 3. GÃ©nÃ©rateur d'images avec augmentation pour l'entraÃ®nement\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_gen_train = ImageDataGenerator(\n",
        "    rescale=1./255,               # Normalisation des pixels\n",
        "    rotation_range=45,            # Rotation alÃ©atoire jusquâ€™Ã  45Â°\n",
        "    width_shift_range=0.15,       # DÃ©calage horizontal\n",
        "    height_shift_range=0.15,      # DÃ©calage vertical\n",
        "    horizontal_flip=True,         # Flip horizontal\n",
        "    zoom_range=0.5                # Zoom jusquâ€™Ã  50%\n",
        ")\n",
        "\n",
        "# ğŸ“¡ 4. GÃ©nÃ©rateur d'entraÃ®nement\n",
        "train_data_gen = image_gen_train.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=train_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# ğŸ§¼ 5. GÃ©nÃ©rateur de validation (sans augmentation)\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# ğŸ§  6. RÃ©entraÃ®nement du modÃ¨le avec les nouvelles donnÃ©es augmentÃ©es\n",
        "history_augmented = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=train_data_gen.samples // batch_size,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=val_data_gen.samples // batch_size,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ğŸ“ˆ 7. Visualisation des performances\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_augmented_training(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Courbes d'exactitude\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Exactitude entraÃ®nement')\n",
        "    plt.plot(epochs_range, val_acc, label='Exactitude validation')\n",
        "    plt.title(\"Exactitude avec augmentation\")\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Courbes de perte\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Perte entraÃ®nement')\n",
        "    plt.plot(epochs_range, val_loss, label='Perte validation')\n",
        "    plt.title(\"Perte avec augmentation\")\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ğŸ” 8. Affichage\n",
        "plot_augmented_training(history_augmented)\n",
        "\n",
        "\n",
        "Found 20000 images belonging to 2 classes.\n",
        "Found 5000 images belonging to 2 classes.\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
        "  self._warn_if_super_not_called()\n",
        "Epoch 1/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1221s 2s/step - accuracy: 0.5220 - loss: 0.7191 - val_accuracy: 0.5727 - val_loss: 0.6753\n",
        "Epoch 2/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1223s 2s/step - accuracy: 0.5661 - loss: 0.6804 - val_accuracy: 0.6226 - val_loss: 0.6515\n",
        "Epoch 3/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1221s 2s/step - accuracy: 0.6134 - loss: 0.6569 - val_accuracy: 0.6841 - val_loss: 0.5932\n",
        "Epoch 4/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1221s 2s/step - accuracy: 0.6570 - loss: 0.6153 - val_accuracy: 0.7388 - val_loss: 0.5344\n",
        "Epoch 5/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1194s 2s/step - accuracy: 0.6872 - loss: 0.5804 - val_accuracy: 0.7612 - val_loss: 0.5084\n",
        "Epoch 6/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1216s 2s/step - accuracy: 0.7054 - loss: 0.5712 - val_accuracy: 0.7716 - val_loss: 0.4868\n",
        "Epoch 7/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1282s 2s/step - accuracy: 0.7192 - loss: 0.5516 - val_accuracy: 0.7628 - val_loss: 0.4979\n",
        "Epoch 8/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1176s 2s/step - accuracy: 0.7203 - loss: 0.5431 - val_accuracy: 0.7684 - val_loss: 0.4809\n",
        "Epoch 9/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1222s 2s/step - accuracy: 0.7265 - loss: 0.5392 - val_accuracy: 0.7726 - val_loss: 0.4817\n",
        "Epoch 10/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1282s 2s/step - accuracy: 0.7370 - loss: 0.5282 - val_accuracy: 0.7945 - val_loss: 0.4349\n",
        "Epoch 11/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1284s 2s/step - accuracy: 0.7491 - loss: 0.5072 - val_accuracy: 0.7879 - val_loss: 0.4510\n",
        "Epoch 12/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1219s 2s/step - accuracy: 0.7581 - loss: 0.5003 - val_accuracy: 0.7961 - val_loss: 0.4381\n",
        "Epoch 13/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1223s 2s/step - accuracy: 0.7642 - loss: 0.4929 - val_accuracy: 0.8005 - val_loss: 0.4241\n",
        "Epoch 14/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1223s 2s/step - accuracy: 0.7669 - loss: 0.4841 - val_accuracy: 0.8167 - val_loss: 0.4115\n",
        "Epoch 15/15\n",
        "625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1222s 2s/step - accuracy: 0.7658 - loss: 0.4799 - val_accuracy: 0.7744 - val_loss: 0.4751\n",
        "\n",
        "InterprÃ©tation :\n",
        "\n",
        "ğŸ“ˆ Courbe d'exactitude (gauche) Exactitude dâ€™entraÃ®nement (bleue) : elle augmente progressivement, atteignant environ 0.78, ce qui montre que le modÃ¨le apprend correctement.\n",
        "\n",
        "Exactitude de validation (orange) : suit une trajectoire similaire et atteint environ 0.80, souvent lÃ©gÃ¨rement supÃ©rieure Ã  celle de lâ€™entraÃ®nement â€” ce qui est un trÃ¨s bon signe.\n",
        "\n",
        "âœ… Conclusion : il n'y a pas de surapprentissage apparent, les deux courbes Ã©voluent ensemble de faÃ§on fluide.\n",
        "\n",
        "ğŸ“‰ Courbe de perte (droite) Perte dâ€™entraÃ®nement (bleue) : diminue rÃ©guliÃ¨rement vers ~0.45, ce qui indique une amÃ©lioration du modÃ¨le.\n",
        "\n",
        "Perte de validation (orange) : commence plus haut (~0.60), puis diminue en parallÃ¨le, atteignant ~0.42, meilleure que la perte dâ€™entraÃ®nement Ã  la fin.\n",
        "\n",
        "âœ… Conclusion : la validation confirme que le modÃ¨le se gÃ©nÃ©ralise bien, probablement grÃ¢ce Ã  lâ€™effet de rÃ©gularisation introduit par lâ€™augmentation.\n",
        "\n",
        "image.png\n",
        "\n",
        "ğŸ“Š Globalement, le modÃ¨le semble plus performant et plus stable que lors du premier entraÃ®nement sans augmentation.\n",
        "\n",
        "âš”ï¸ Comparaison directe entre les deux entraÃ®nements\n",
        "\n",
        "image.png image.png\n",
        "\n",
        "ğŸ’¡ Ce quâ€™on peut conclure Le modÃ¨le sans augmentation atteint un meilleur score brut de validation, mais montre des signes de surapprentissage lÃ©ger : fluctuation de la perte et exactitude plus haute que lâ€™entraÃ®nement.\n",
        "\n",
        "Le modÃ¨le avec augmentation est plus rÃ©gulier, robuste et gÃ©nÃ©ralise mieux â€” mÃªme si les scores ne sont pas aussi â€œhautsâ€, leur stabilitÃ© est bien plus rassurante pour des cas rÃ©els.\n",
        "\n",
        "En rÃ©sumÃ© :\n",
        "\n",
        "ğŸ¯ Lâ€™augmentation de donnÃ©es agit comme un bouclier contre la suradaptation. Elle rend le modÃ¨le moins spectaculaire dans les scores dâ€™entraÃ®nement, mais beaucoup plus fiable dans la durÃ©e."
      ],
      "metadata": {
        "id": "yuLzH_phM19r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}