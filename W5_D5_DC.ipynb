{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJdGLXrkMvwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Daily Challenge\n",
        "\n",
        "1. Preprocess the Data:\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "Mounted at /content/drive\n",
        "\n",
        "# Importations nécessaires\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# 2. Définir les chemins\n",
        "drive_zip_path = '/content/drive/MyDrive/Colab Notebooks/W5/D5/Dogs vs Cats.zip'  # Chemin dans Drive\n",
        "extract_path = '/content/cats_and_dogs'\n",
        "original_train_dir = os.path.join(extract_path, 'train/train')  # Adapté à la structure réelle\n",
        "processed_train_dir = os.path.join(extract_path, 'processed_train')\n",
        "validation_dir = os.path.join(extract_path, 'validation')\n",
        "# 3. Nettoyage initial et création des dossiers\n",
        "!rm -rf {extract_path}  # Suppression complète avant extraction\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "# 4. Copie depuis Drive vers Colab\n",
        "!cp \"{drive_zip_path}\" \"{extract_path}/Dogs_vs_Cats.zip\"\n",
        "# 5. Extraction\n",
        "with zipfile.ZipFile(os.path.join(extract_path, 'Dogs_vs_Cats.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "# 6. Vérification de la structure\n",
        "print(\"Structure après extraction:\")\n",
        "!find {extract_path} -type d | sort\n",
        "print(\"\\nContenu du dossier train/train:\")\n",
        "!ls -la {original_train_dir} | head -10\n",
        "# 7. Fonction pour organiser les fichiers\n",
        "def organize_images(source_dir, train_dest, val_dest, test_size=0.2):\n",
        "    \"\"\"Organise les images en train/validation avec séparation par classe\"\"\"\n",
        "    os.makedirs(train_dest, exist_ok=True)\n",
        "    os.makedirs(val_dest, exist_ok=True)\n",
        "    # Créer sous-dossiers cats/dogs\n",
        "    for folder in [train_dest, val_dest]:\n",
        "        for class_name in ['cats', 'dogs']:\n",
        "            os.makedirs(os.path.join(folder, class_name), exist_ok=True)\n",
        "    # Lister les fichiers images\n",
        "    all_files = [f for f in os.listdir(source_dir)\n",
        "                if os.path.isfile(os.path.join(source_dir, f))\n",
        "                and f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    if not all_files:\n",
        "        raise ValueError(f\"Aucune image trouvée dans {source_dir}\")\n",
        "    # Séparation train/validation\n",
        "    train_files, val_files = train_test_split(all_files, test_size=test_size, random_state=42)\n",
        "    # Déplacement des fichiers\n",
        "    for file_list, dest in [(train_files, train_dest), (val_files, val_dest)]:\n",
        "        for file in file_list:\n",
        "            src = os.path.join(source_dir, file)\n",
        "            class_folder = 'cats' if 'cat' in file.lower() else 'dogs'\n",
        "            dst = os.path.join(dest, class_folder, file)\n",
        "            shutil.move(src, dst)\n",
        "# 8. Organiser les images\n",
        "organize_images(\n",
        "    source_dir=original_train_dir,\n",
        "    train_dest=processed_train_dir,\n",
        "    val_dest=validation_dir,\n",
        "    test_size=0.2\n",
        ")\n",
        "# 9. Vérification après organisation\n",
        "print(\"\\nStructure après organisation:\")\n",
        "!find {extract_path} -type d | sort\n",
        "print(\"\\nContenu de processed_train:\")\n",
        "!ls -la {processed_train_dir} | head -10\n",
        "print(\"\\nContenu de validation:\")\n",
        "!ls -la {validation_dir} | head -10\n",
        "# 10. Paramètres des images\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "# 11. Augmentation des données\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# 12. Création des générateurs\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    processed_train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "# 13. Affichage des informations\n",
        "print(\"\\nClasses d'entraînement:\", train_generator.class_indices)\n",
        "print(\"Nombre d'images d'entraînement:\", train_generator.samples)\n",
        "print(\"Nombre d'images de validation:\", validation_generator.samples)\n",
        "\n",
        "Structure après extraction:\n",
        "/content/cats_and_dogs\n",
        "/content/cats_and_dogs/test\n",
        "/content/cats_and_dogs/test/test\n",
        "/content/cats_and_dogs/train\n",
        "/content/cats_and_dogs/train/train\n",
        "\n",
        "Contenu du dossier train/train:\n",
        "total 609272\n",
        "drwxr-xr-x 2 root root 778240 Jul 11 14:07 .\n",
        "drwxr-xr-x 3 root root   4096 Jul 11 14:07 ..\n",
        "-rw-r--r-- 1 root root  12414 Jul 11 14:07 cat.0.jpg\n",
        "-rw-r--r-- 1 root root  21944 Jul 11 14:07 cat.10000.jpg\n",
        "-rw-r--r-- 1 root root  27322 Jul 11 14:07 cat.10001.jpg\n",
        "-rw-r--r-- 1 root root  25723 Jul 11 14:07 cat.10002.jpg\n",
        "-rw-r--r-- 1 root root  28035 Jul 11 14:07 cat.10003.jpg\n",
        "-rw-r--r-- 1 root root  12973 Jul 11 14:07 cat.10004.jpg\n",
        "-rw-r--r-- 1 root root   8245 Jul 11 14:07 cat.10005.jpg\n",
        "\n",
        "Structure après organisation:\n",
        "/content/cats_and_dogs\n",
        "/content/cats_and_dogs/processed_train\n",
        "/content/cats_and_dogs/processed_train/cats\n",
        "/content/cats_and_dogs/processed_train/dogs\n",
        "/content/cats_and_dogs/test\n",
        "/content/cats_and_dogs/test/test\n",
        "/content/cats_and_dogs/train\n",
        "/content/cats_and_dogs/train/train\n",
        "/content/cats_and_dogs/validation\n",
        "/content/cats_and_dogs/validation/cats\n",
        "/content/cats_and_dogs/validation/dogs\n",
        "\n",
        "Contenu de processed_train:\n",
        "total 572\n",
        "drwxr-xr-x 4 root root   4096 Jul 11 14:07 .\n",
        "drwxr-xr-x 6 root root   4096 Jul 11 14:07 ..\n",
        "drwxr-xr-x 2 root root 286720 Jul 11 14:07 cats\n",
        "drwxr-xr-x 2 root root 282624 Jul 11 14:07 dogs\n",
        "\n",
        "Contenu de validation:\n",
        "total 152\n",
        "drwxr-xr-x 4 root root  4096 Jul 11 14:07 .\n",
        "drwxr-xr-x 6 root root  4096 Jul 11 14:07 ..\n",
        "drwxr-xr-x 2 root root 69632 Jul 11 14:07 cats\n",
        "drwxr-xr-x 2 root root 69632 Jul 11 14:07 dogs\n",
        "Found 20000 images belonging to 2 classes.\n",
        "Found 5000 images belonging to 2 classes.\n",
        "\n",
        "Classes d'entraînement: {'cats': 0, 'dogs': 1}\n",
        "Nombre d'images d'entraînement: 20000\n",
        "Nombre d'images de validation: 5000\n",
        "2. Build the Model:\n",
        "\n",
        "Le script ci-dessous est un CNN avec trois couches convolutionnelles, chacune suivie d'un max-pooling, puis une couche de flatten, une couche fully connectée avec Dropout, et enfin la couche de sortie adaptée à la classification binaire. La compilation utilise l'optimiseur Adam et la fonction de perte binaire croisée, ce qui est standard pour ce type de problème.\n",
        "\n",
        "\n",
        "# Importation des modules nécessaires\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Définition des dimensions des images (selon ton script initial)\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "# 2. Construction du modèle CNN\n",
        "model = Sequential()\n",
        "\n",
        "# Première couche convolutionnelle avec ReLU et max-pooling\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Deuxième couche convolutionnelle\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Troisième couche convolutionnelle\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten pour transformer la sortie en vecteur\n",
        "model.add(Flatten())\n",
        "\n",
        "# Couche fully connectée avec 512 unités et ReLU\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Dropout pour réduire le surapprentissage\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Couche de sortie avec sigmoid pour la classification binaire\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilation du modèle avec Adam et binary cross-entropy\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
        "Model: \"sequential\"\n",
        "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
        "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
        "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
        "│ conv2d (Conv2D)                 │ (None, 148, 148, 32)   │           896 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ max_pooling2d (MaxPooling2D)    │ (None, 74, 74, 32)     │             0 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ conv2d_1 (Conv2D)               │ (None, 72, 72, 64)     │        18,496 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ max_pooling2d_1 (MaxPooling2D)  │ (None, 36, 36, 64)     │             0 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ conv2d_2 (Conv2D)               │ (None, 34, 34, 128)    │        73,856 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ max_pooling2d_2 (MaxPooling2D)  │ (None, 17, 17, 128)    │             0 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ flatten (Flatten)               │ (None, 36992)          │             0 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ dense (Dense)                   │ (None, 512)            │    18,940,416 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ dropout (Dropout)               │ (None, 512)            │             0 │\n",
        "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
        "│ dense_1 (Dense)                 │ (None, 1)              │           513 │\n",
        "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
        " Total params: 19,034,177 (72.61 MB)\n",
        " Trainable params: 19,034,177 (72.61 MB)\n",
        " Non-trainable params: 0 (0.00 B)\n",
        "3. Train the Model:\n",
        "\n",
        "\n",
        "# Entraîner le modèle pendant 15 époques\n",
        "history = model.fit(\n",
        "    train_generator,              # Générateur de données d'entraînement avec augmentation\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,  # Nombre de pas par époque\n",
        "    epochs=EPOCHS,                # Nombre total d'époques d'entraînement\n",
        "    validation_data=validation_generator,  # Données de validation pour évaluer les performances\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,  # Nombre de pas de validation par époque\n",
        "    verbose=1                     # Affiche la progression pendant l'entraînement\n",
        ")\n",
        "\n",
        "# Affichage des performances d'entraînement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fonctions auxiliaires pour visualiser l'exactitude et la perte\n",
        "def plot_training_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(EPOCHS)\n",
        "\n",
        "    # Tracer la courbe d'exactitude\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Exactitude entraînement')\n",
        "    plt.plot(epochs_range, val_acc, label='Exactitude validation')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Exactitude au fil des époques')\n",
        "\n",
        "    # Tracer la courbe de perte\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Perte entraînement')\n",
        "    plt.plot(epochs_range, val_loss, label='Perte validation')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Perte au fil des époques')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualiser les courbes\n",
        "plot_training_history(history)\n",
        "\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
        "  self._warn_if_super_not_called()\n",
        "Epoch 1/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 148s 226ms/step - accuracy: 0.5524 - loss: 0.6840 - val_accuracy: 0.6186 - val_loss: 0.6358\n",
        "Epoch 2/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 193s 220ms/step - accuracy: 0.6133 - loss: 0.6497 - val_accuracy: 0.7194 - val_loss: 0.5681\n",
        "Epoch 3/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 141s 218ms/step - accuracy: 0.6756 - loss: 0.5992 - val_accuracy: 0.7286 - val_loss: 0.5331\n",
        "Epoch 4/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 138s 221ms/step - accuracy: 0.7069 - loss: 0.5698 - val_accuracy: 0.7432 - val_loss: 0.5107\n",
        "Epoch 5/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 138s 220ms/step - accuracy: 0.7130 - loss: 0.5575 - val_accuracy: 0.7628 - val_loss: 0.4931\n",
        "Epoch 6/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 138s 221ms/step - accuracy: 0.7250 - loss: 0.5426 - val_accuracy: 0.7778 - val_loss: 0.4704\n",
        "Epoch 7/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 140s 218ms/step - accuracy: 0.7382 - loss: 0.5254 - val_accuracy: 0.7770 - val_loss: 0.4733\n",
        "Epoch 8/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 137s 219ms/step - accuracy: 0.7458 - loss: 0.5059 - val_accuracy: 0.8019 - val_loss: 0.4321\n",
        "Epoch 9/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 141s 218ms/step - accuracy: 0.7621 - loss: 0.4911 - val_accuracy: 0.7792 - val_loss: 0.4594\n",
        "Epoch 10/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 142s 218ms/step - accuracy: 0.7795 - loss: 0.4705 - val_accuracy: 0.8093 - val_loss: 0.4295\n",
        "Epoch 11/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 136s 217ms/step - accuracy: 0.7875 - loss: 0.4502 - val_accuracy: 0.8161 - val_loss: 0.4060\n",
        "Epoch 12/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 203s 315ms/step - accuracy: 0.7870 - loss: 0.4508 - val_accuracy: 0.8249 - val_loss: 0.3974\n",
        "Epoch 13/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 202s 315ms/step - accuracy: 0.7900 - loss: 0.4452 - val_accuracy: 0.8313 - val_loss: 0.3885\n",
        "Epoch 14/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 136s 218ms/step - accuracy: 0.8021 - loss: 0.4272 - val_accuracy: 0.8267 - val_loss: 0.3861\n",
        "Epoch 15/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 142s 218ms/step - accuracy: 0.8054 - loss: 0.4235 - val_accuracy: 0.8393 - val_loss: 0.3657\n",
        "\n",
        "🔍 Lecture des courbes\n",
        "\n",
        "Exactitude au fil des époques (gauche)\n",
        "🔵 Entraînement : progression régulière jusqu’à ~0.80, ce qui montre que le modèle apprend de façon constante.\n",
        "\n",
        "🟠 Validation : démarre autour de 0.60 et atteint ~0.83, parfois plus élevée que l’entraînement — ce qui peut indiquer une bonne généralisation ou des effets de régularisation.\n",
        "\n",
        "Perte au fil des époques (droite)\n",
        "🔵 Entraînement : la perte diminue progressivement vers ~0.40, ce qui confirme l’apprentissage.\n",
        "\n",
        "🟠 Validation : perte en baisse rapide au départ, puis fluctue légèrement, terminant autour de ~0.35 — ce qui est très bon.\n",
        "\n",
        "🧠 Ce que ça révèle :\n",
        "\n",
        "image.png\n",
        "\n",
        "5. Bonus:\n",
        "\n",
        "\n",
        "# 📂 1. Définir les chemins (à adapter si nécessaire)\n",
        "train_dir = '/content/cats_and_dogs/processed_train'\n",
        "validation_dir = '/content/cats_and_dogs/validation'\n",
        "\n",
        "# ⚙️ 2. Paramètres de traitement\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "batch_size = 32\n",
        "EPOCHS = 15\n",
        "\n",
        "# 🧰 3. Générateur d'images avec augmentation pour l'entraînement\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_gen_train = ImageDataGenerator(\n",
        "    rescale=1./255,               # Normalisation des pixels\n",
        "    rotation_range=45,            # Rotation aléatoire jusqu’à 45°\n",
        "    width_shift_range=0.15,       # Décalage horizontal\n",
        "    height_shift_range=0.15,      # Décalage vertical\n",
        "    horizontal_flip=True,         # Flip horizontal\n",
        "    zoom_range=0.5                # Zoom jusqu’à 50%\n",
        ")\n",
        "\n",
        "# 📡 4. Générateur d'entraînement\n",
        "train_data_gen = image_gen_train.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=train_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# 🧼 5. Générateur de validation (sans augmentation)\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# 🧠 6. Réentraînement du modèle avec les nouvelles données augmentées\n",
        "history_augmented = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=train_data_gen.samples // batch_size,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=val_data_gen.samples // batch_size,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 📈 7. Visualisation des performances\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_augmented_training(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Courbes d'exactitude\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Exactitude entraînement')\n",
        "    plt.plot(epochs_range, val_acc, label='Exactitude validation')\n",
        "    plt.title(\"Exactitude avec augmentation\")\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Courbes de perte\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Perte entraînement')\n",
        "    plt.plot(epochs_range, val_loss, label='Perte validation')\n",
        "    plt.title(\"Perte avec augmentation\")\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 🔍 8. Affichage\n",
        "plot_augmented_training(history_augmented)\n",
        "\n",
        "\n",
        "Found 20000 images belonging to 2 classes.\n",
        "Found 5000 images belonging to 2 classes.\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
        "  self._warn_if_super_not_called()\n",
        "Epoch 1/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1221s 2s/step - accuracy: 0.5220 - loss: 0.7191 - val_accuracy: 0.5727 - val_loss: 0.6753\n",
        "Epoch 2/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1223s 2s/step - accuracy: 0.5661 - loss: 0.6804 - val_accuracy: 0.6226 - val_loss: 0.6515\n",
        "Epoch 3/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1221s 2s/step - accuracy: 0.6134 - loss: 0.6569 - val_accuracy: 0.6841 - val_loss: 0.5932\n",
        "Epoch 4/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1221s 2s/step - accuracy: 0.6570 - loss: 0.6153 - val_accuracy: 0.7388 - val_loss: 0.5344\n",
        "Epoch 5/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1194s 2s/step - accuracy: 0.6872 - loss: 0.5804 - val_accuracy: 0.7612 - val_loss: 0.5084\n",
        "Epoch 6/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1216s 2s/step - accuracy: 0.7054 - loss: 0.5712 - val_accuracy: 0.7716 - val_loss: 0.4868\n",
        "Epoch 7/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1282s 2s/step - accuracy: 0.7192 - loss: 0.5516 - val_accuracy: 0.7628 - val_loss: 0.4979\n",
        "Epoch 8/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1176s 2s/step - accuracy: 0.7203 - loss: 0.5431 - val_accuracy: 0.7684 - val_loss: 0.4809\n",
        "Epoch 9/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1222s 2s/step - accuracy: 0.7265 - loss: 0.5392 - val_accuracy: 0.7726 - val_loss: 0.4817\n",
        "Epoch 10/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1282s 2s/step - accuracy: 0.7370 - loss: 0.5282 - val_accuracy: 0.7945 - val_loss: 0.4349\n",
        "Epoch 11/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1284s 2s/step - accuracy: 0.7491 - loss: 0.5072 - val_accuracy: 0.7879 - val_loss: 0.4510\n",
        "Epoch 12/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1219s 2s/step - accuracy: 0.7581 - loss: 0.5003 - val_accuracy: 0.7961 - val_loss: 0.4381\n",
        "Epoch 13/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1223s 2s/step - accuracy: 0.7642 - loss: 0.4929 - val_accuracy: 0.8005 - val_loss: 0.4241\n",
        "Epoch 14/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1223s 2s/step - accuracy: 0.7669 - loss: 0.4841 - val_accuracy: 0.8167 - val_loss: 0.4115\n",
        "Epoch 15/15\n",
        "625/625 ━━━━━━━━━━━━━━━━━━━━ 1222s 2s/step - accuracy: 0.7658 - loss: 0.4799 - val_accuracy: 0.7744 - val_loss: 0.4751\n",
        "\n",
        "Interprétation :\n",
        "\n",
        "📈 Courbe d'exactitude (gauche) Exactitude d’entraînement (bleue) : elle augmente progressivement, atteignant environ 0.78, ce qui montre que le modèle apprend correctement.\n",
        "\n",
        "Exactitude de validation (orange) : suit une trajectoire similaire et atteint environ 0.80, souvent légèrement supérieure à celle de l’entraînement — ce qui est un très bon signe.\n",
        "\n",
        "✅ Conclusion : il n'y a pas de surapprentissage apparent, les deux courbes évoluent ensemble de façon fluide.\n",
        "\n",
        "📉 Courbe de perte (droite) Perte d’entraînement (bleue) : diminue régulièrement vers ~0.45, ce qui indique une amélioration du modèle.\n",
        "\n",
        "Perte de validation (orange) : commence plus haut (~0.60), puis diminue en parallèle, atteignant ~0.42, meilleure que la perte d’entraînement à la fin.\n",
        "\n",
        "✅ Conclusion : la validation confirme que le modèle se généralise bien, probablement grâce à l’effet de régularisation introduit par l’augmentation.\n",
        "\n",
        "image.png\n",
        "\n",
        "📊 Globalement, le modèle semble plus performant et plus stable que lors du premier entraînement sans augmentation.\n",
        "\n",
        "⚔️ Comparaison directe entre les deux entraînements\n",
        "\n",
        "image.png image.png\n",
        "\n",
        "💡 Ce qu’on peut conclure Le modèle sans augmentation atteint un meilleur score brut de validation, mais montre des signes de surapprentissage léger : fluctuation de la perte et exactitude plus haute que l’entraînement.\n",
        "\n",
        "Le modèle avec augmentation est plus régulier, robuste et généralise mieux — même si les scores ne sont pas aussi “hauts”, leur stabilité est bien plus rassurante pour des cas réels.\n",
        "\n",
        "En résumé :\n",
        "\n",
        "🎯 L’augmentation de données agit comme un bouclier contre la suradaptation. Elle rend le modèle moins spectaculaire dans les scores d’entraînement, mais beaucoup plus fiable dans la durée."
      ],
      "metadata": {
        "id": "yuLzH_phM19r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}