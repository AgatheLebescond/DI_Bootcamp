{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfca3eb",
   "metadata": {},
   "source": [
    "# D√©fi quotidien : cr√©er un d√©tecteur de texte IA bas√© sur GAN\n",
    "\n",
    "\n",
    "üë©‚Äçüè´ üë©üèø‚Äçüè´ Ce que vous apprendrez\n",
    "Comment former un r√©seau antagoniste g√©n√©ratif (GAN) pour d√©tecter le texte g√©n√©r√© par l'IA.\n",
    "Comment utiliser un mod√®le BERT pr√©-entra√Æn√© pour la classification de s√©quences.\n",
    "Comment pr√©traiter les donn√©es textuelles et les tokeniser pour les mod√®les d'apprentissage en profondeur.\n",
    "Comment √©valuer les performances du mod√®le √† l‚Äôaide des scores AUC.\n",
    "Comment affiner et optimiser les mod√®les d‚Äôapprentissage en profondeur.\n",
    "Comment effectuer des inf√©rences et g√©n√©rer des pr√©dictions sur des donn√©es de test.\n",
    "\n",
    "\n",
    "üõ†Ô∏è Ce que vous allez cr√©er\n",
    "Un mod√®le bas√© sur GAN qui d√©tecte le texte g√©n√©r√© par l'IA √† l'aide d'int√©grations d'un mod√®le BERT.\n",
    "Un pipeline de formation qui exploite un r√©seau discriminateur et g√©n√©rateur.\n",
    "Un mod√®le qui s'am√©liore en fonction des scores AUC pour la stabilit√© dans la formation.\n",
    "Un fichier de soumission final avec des pr√©dictions sur l'ensemble de donn√©es de test.\n",
    "\n",
    "\n",
    "Ensemble de donn√©es\n",
    "Vous pouvez trouver l'ensemble de donn√©es pour cet exercice ici : Ensemble de donn√©es\n",
    "\n",
    "\n",
    "\n",
    "T√¢che\n",
    "Pour le d√©fi d'aujourd'hui, vous disposez du code final avec des parties √† compl√©ter. Si vous voyez un ¬´ √Ä FAIRE ¬ª, cela signifie que vous devez √©crire du code. Compl√©tez-les toutes.\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_PATH = TODO\n",
    "TEST_PATH = TODO\n",
    "PROMPT_PATH = TODO\n",
    "\n",
    "src_train = TODO\n",
    "src_prompt = TODO\n",
    "\n",
    "src_sub = TODO\n",
    "\n",
    "\n",
    "### Model preparation\n",
    "\n",
    "tokenizer_save_path = TODO\n",
    "model_save_path = TODO\n",
    "\n",
    "tokenizer = TODO\n",
    "pretrained_model = TODO\n",
    "embedding_model = TODO\n",
    "\n",
    "\"\"\"# Parameter definition\"\"\"\n",
    "\n",
    "train_batch_size = TODO\n",
    "test_batch_size = TODO\n",
    "lr = TODO\n",
    "beta1 = TODO\n",
    "nz = 100  # Dimensions of the latent vector\n",
    "num_epochs = TODO\n",
    "num_hidden_layers = TODO\n",
    "train_ratio = TODO\n",
    "\n",
    "\"\"\"# Data Preparation\"\"\"\n",
    "\n",
    "class GANDAIGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "all_num = TODO\n",
    "train_num = TODO\n",
    "test_num = TODO\n",
    "\n",
    "\n",
    "train_set = TODO\n",
    "test_set = pd.concat([\n",
    "    TODO,\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataset = TODO\n",
    "test_dataset = TODO\n",
    "\n",
    "train_loader = TODO\n",
    "test_loader = TODO\n",
    "\n",
    "\"\"\"# Generator definition\"\"\"\n",
    "\n",
    "config = BertConfig(num_hidden_layers=num_hidden_layers)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, 256 * 128)\n",
    "\n",
    "        self.conv_net = nn.Sequential(\n",
    "            TODO\n",
    "        )\n",
    "        self.bert_encoder = BertEncoder(config)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        TODO\n",
    "        return x\n",
    "\n",
    "\"\"\"# Discriminator definition\"\"\"\n",
    "\n",
    "class SumBertPooler(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        sum_hidden = hidden_states.sum(dim=1)\n",
    "        sum_mask = sum_hidden.sum(1).unsqueeze(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "\n",
    "        mean_embeddings = sum_hidden / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert_encoder = BertEncoder(config)\n",
    "        self.bert_encoder.layer = nn.ModuleList([\n",
    "            layer for layer in pretrained_model.bert.encoder.layer[:6]\n",
    "        ])\n",
    "        self.pooler = SumBertPooler()\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            TODO\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.bert_encoder(input)\n",
    "        out = self.pooler(out.last_hidden_state)\n",
    "        out = self.classifier(out)\n",
    "        return torch.sigmoid(out).view(-1)\n",
    "\n",
    "\"\"\"# Training\"\"\"\n",
    "\n",
    "### Commented out IPython magic to ensure Python compatibility.\n",
    "def eval_auc(model):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            encodings = TODO\n",
    "            input_ids = TODO\n",
    "            token_type_ids = TODO\n",
    "            embeded = TODO\n",
    "            embeded =TODO\n",
    "            attention_mask = TODO\n",
    "            label = batch[1].float().to(device)\n",
    "\n",
    "            outputs = model(embeded)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(label.cpu().numpy())\n",
    "\n",
    "    auc = TODO\n",
    "    print(\"AUC:\", auc)\n",
    "    return auc\n",
    "\n",
    "def get_model_info_dict(model, epoch, auc_score):\n",
    "    current_device = next(model.parameters()).device\n",
    "    model.to('cpu')\n",
    "\n",
    "    model_info = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'auc_score': auc_score,\n",
    "    }\n",
    "\n",
    "    model.to(current_device)\n",
    "    return model_info\n",
    "\n",
    "def preparation_embedding(texts):\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = encodings['input_ids']\n",
    "    token_type_ids = encodings['token_type_ids']\n",
    "    embeded = embedding_model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "    return embeded\n",
    "\n",
    "def GAN_step(optimizerG, optimizerD, netG, netD, real_data, label, epoch, i):\n",
    "    netD.zero_grad()\n",
    "    batch_size = real_data.size(0)\n",
    "\n",
    "    output = netD(real_data)\n",
    "    errD_real = criterion(output, label)\n",
    "    errD_real.backward()\n",
    "    D_x = output.mean().item()\n",
    "\n",
    "    noise = torch.randn(batch_size, nz, device=device)\n",
    "    fake_data = netG(noise).last_hidden_state\n",
    "    label.fill_(1)\n",
    "    output = netD(fake_data.detach())\n",
    "    errD_fake = criterion(output, label)\n",
    "    errD_fake.backward()\n",
    "    D_G_z1 = output.mean().item()\n",
    "    errD = errD_real + errD_fake\n",
    "    optimizerD.step()\n",
    "\n",
    "    netG.zero_grad()\n",
    "    label.fill_(0)\n",
    "    output = netD(fake_data)\n",
    "    errG = criterion(output, label)\n",
    "    errG.backward()\n",
    "    D_G_z2 = output.mean().item()\n",
    "    optimizerG.step()\n",
    "    if i % 50 == 0:\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "###               % (epoch, num_epochs, i, len(train_loader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "    return optimizerG, optimizerD, netG, netD\n",
    "\n",
    "netG = TODO\n",
    "netD = TODO\n",
    "\n",
    "criterion = TODO\n",
    "optimizerD = TODO\n",
    "optimizerG = TODO\n",
    "\n",
    "model_infos = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        with torch.no_grad():\n",
    "            embeded = preparation_embedding(data[0])\n",
    "\n",
    "        optimizerG, optimizerD, netG, netD = GAN_step(\n",
    "            optimizerG=TODO,\n",
    "            optimizerD=TODO,\n",
    "            netG=netG,\n",
    "            netD=netD,\n",
    "            real_data=embeded.to(device),\n",
    "            label=data[1].float().to(device),\n",
    "            epoch=epoch, i=i)\n",
    "\n",
    "    auc_score = TODO\n",
    "    model_infos.append(get_model_info_dict(netD, epoch, auc_score))\n",
    "\n",
    "print('Train completeÔºÅ')\n",
    "\n",
    "\"\"\"# Inference\"\"\"\n",
    "\n",
    "max_auc_model_info = TODO\n",
    "model = Discriminator()\n",
    "model.load_state_dict(max_auc_model_info['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "class InferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "sub_dataset = TODO\n",
    "\n",
    "inference_loader = TODO\n",
    "\n",
    "sub_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in inference_loader:\n",
    "        encodings = TODO\n",
    "        input_ids = TODO\n",
    "        token_type_ids = TODO\n",
    "        embeded = TODO\n",
    "        embeded = embeded.to(device)\n",
    "\n",
    "        outputs = model(embeded)\n",
    "        sub_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "sub_ans_df = TODO\n",
    "print(sub_ans_df)\n",
    "\n",
    "\n",
    "Instructions :\n",
    "1. T√©l√©chargez l'ensemble de donn√©es\n",
    "\n",
    "T√©l√©chargez la cl√© API Kaggle.\n",
    "D√©placez la cl√© dans le bon r√©pertoire et d√©finissez les autorisations, vous pouvez accepter les r√®gles des comp√©titions dans Rulesou dans Participate.\n",
    "T√©l√©chargez et d√©compressez le jeu de donn√©es.\n",
    "ou :\n",
    "T√©l√©charger manuellement depuis Kaggle\n",
    "2. Charger les donn√©es\n",
    "\n",
    "Lisez les ensembles de donn√©es de formation et de test √† l‚Äôaide de pandas.\n",
    "Afficher les statistiques de base et la structure de l'ensemble de donn√©es.\n",
    "3. Pr√©parez le mod√®le\n",
    "\n",
    "Chargez le tokeniseur BERT et le mod√®le pr√©-entra√Æn√© pour la classification des s√©quences : bert-base-uncased.\n",
    "Extraire les int√©grations du mod√®le BERT √† utiliser dans le framework GAN.\n",
    "4. D√©finir les hyperparam√®tres\n",
    "\n",
    "D√©finissez les tailles de lots, les taux d‚Äôapprentissage, les dimensions des vecteurs latents et les √©poques d‚Äôapprentissage.\n",
    "5. Pr√©parez les donn√©es pour la formation\n",
    "\n",
    "Cr√©ez une classe d‚Äôensemble de donn√©es PyTorch pour g√©rer les donn√©es textuelles.\n",
    "Divisez les donn√©es en ensembles d‚Äôentra√Ænement et de test.\n",
    "Utilisez DataLoader pour charger des lots efficacement.\n",
    "6. D√©finir le mod√®le de g√©n√©rateur\n",
    "\n",
    "Cr√©ez un r√©seau neuronal qui g√©n√®re des int√©grations de texte √† l'aide de couches ConvTranspose1D.\n",
    "Incorporer un encodeur BERT dans le g√©n√©rateur.\n",
    "7. D√©finir le mod√®le discriminateur\n",
    "\n",
    "Extraire et modifier des couches √† partir d‚Äôun mod√®le BERT pr√©-entra√Æn√©.\n",
    "Mettre en ≈ìuvre un m√©canisme de regroupement pour la classification de texte.\n",
    "Construisez une t√™te de classification en utilisant des couches enti√®rement connect√©es.\n",
    "8. Entra√Æner le mod√®le\n",
    "\n",
    "Mettre en ≈ìuvre une boucle de formation GAN.\n",
    "Entra√Ænez le g√©n√©rateur √† produire des plongements qui trompent le discriminateur.\n",
    "Entra√Ænez le discriminateur √† diff√©rencier les plongements r√©els et g√©n√©r√©s.\n",
    "√âvaluez le mod√®le √† l‚Äôaide des scores AUC pour surveiller la stabilit√© de la formation.\n",
    "9. Effectuer une inf√©rence\n",
    "\n",
    "Chargez le mod√®le discriminateur le plus performant en fonction des scores AUC.\n",
    "Traitez les donn√©es de test via le mod√®le pour g√©n√©rer des pr√©dictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9fb47a",
   "metadata": {},
   "source": [
    "## √âtape 1 : T√©l√©chargement et pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd76b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 1 : Importation des librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638bca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu du dossier './data' :\n",
      "['sample_submission.csv', 'test_essays.csv', 'train_essays.csv', 'train_prompts.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Contenu du dossier './data' :\")\n",
    "print(os.listdir(\"data\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5dc80e",
   "metadata": {},
   "source": [
    "###  Fichiers disponibles :\n",
    "\n",
    "1. **`train_essays.csv`**\n",
    "   ‚û§ Donn√©es d'entra√Ænement principales : probablement des essais annot√©s (humain vs IA).\n",
    "   ‚û§ Contient s√ªrement les colonnes comme : `id`, `prompt_id`, `text`, `generated`, etc.\n",
    "\n",
    "2. **`train_prompts.csv`**\n",
    "   ‚û§ D√©tails sur les prompts associ√©s aux essais.\n",
    "   ‚û§ Colonnes : `prompt_id`, `prompt_name`, `instructions`, `source_text`.\n",
    "\n",
    "3. **`test_essays.csv`**\n",
    "   ‚û§ Corpus √† pr√©dire (texte sans labels).\n",
    "   ‚û§ Contient les essais de test : probablement avec `id`, `prompt_id`, `text`.\n",
    "\n",
    "4. **`sample_submission.csv`**\n",
    "   ‚û§ Format attendu pour la soumission (structure `id,generated`).\n",
    "   ‚û§ Sert de guide pour construire `submission.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusion :\n",
    "\n",
    "Il y a toutes les composantes n√©cessaires pour :\n",
    "\n",
    "* L‚Äôentra√Ænement supervis√©,\n",
    "* La g√©n√©ration de pr√©dictions,\n",
    "* La soumission dans le bon format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09872083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles dans train_prompts.csv :\n",
      "['prompt_id', 'prompt_name', 'instructions', 'source_text']\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes disponibles dans train_prompts.csv :\")\n",
    "print(prompt_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0550a48",
   "metadata": {},
   "source": [
    "Les colonnes de `train_prompts.csv` indiquent que ce fichier contient les **descriptions des consignes** associ√©es aux essais. Voici leur r√¥le :\n",
    "\n",
    "---\n",
    "\n",
    "###  D√©tail des colonnes :\n",
    "\n",
    "* **`prompt_id`** : identifiant unique du prompt (cl√© primaire, sert √† relier aux essais dans `train_essays.csv` via `prompt_id`).\n",
    "\n",
    "* **`prompt_name`** : nom ou titre du prompt (indicatif, pour lecture humaine).\n",
    "\n",
    "* **`instructions`** : consigne donn√©e √† l‚Äôauteur de l‚Äôessai (ex : ‚Äú√©cris un argumentaire sur‚Ä¶‚Äù).\n",
    "\n",
    "* **`source_text`** : texte de r√©f√©rence (ex : un extrait √† analyser ou commenter dans l‚Äôessai).\n",
    "\n",
    "---\n",
    "\n",
    "###  Utilit√© :\n",
    "\n",
    "Ce fichier est essentiel pour :\n",
    "\n",
    "* Comprendre le contexte de chaque essai.\n",
    "* Enrichir les embeddings avec les consignes ou sources.\n",
    "* Faire de l‚Äôaugmentation de donn√©es ou du fine-tuning contextuel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff90189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Dimensions :\n",
      "Train: (1378, 4)\n",
      "Test : (3, 3)\n",
      "Prompts: (2, 4)\n",
      "\n",
      "üß± Types de donn√©es (train):\n",
      "id           object\n",
      "prompt_id     int64\n",
      "text         object\n",
      "generated     int64\n",
      "dtype: object\n",
      "\n",
      "‚ùì Valeurs manquantes (train) :\n",
      "id           0\n",
      "prompt_id    0\n",
      "text         0\n",
      "generated    0\n",
      "dtype: int64\n",
      "\n",
      "üìå Colonnes disponibles :\n",
      "Train : ['id', 'prompt_id', 'text', 'generated']\n",
      "Test  : ['id', 'prompt_id', 'text']\n",
      "Prompts : ['prompt_id', 'prompt_name', 'instructions', 'source_text']\n",
      "\n",
      "üìù Exemples (train) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generated",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dc28a126-b1c8-43a4-829a-202a46b5bfdc",
       "rows": [
        [
         "0",
         "0059830c",
         "0",
         "Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and built the first ModelT. Cars have played a major role in our every day lives since then. But now, people are starting to question if limiting car usage would be a good thing. To me, limiting the use of cars might be a good thing to do.\n\nIn like matter of this, article, \"In German Suburb, Life Goes On Without Cars,\" by Elizabeth Rosenthal states, how automobiles are the linchpin of suburbs, where middle class families from either Shanghai or Chicago tend to make their homes. Experts say how this is a huge impediment to current efforts to reduce greenhouse gas emissions from tailpipe. Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe...and up to 50 percent in some carintensive areas in the United States. Cars are the main reason for the greenhouse gas emissions because of a lot of people driving them around all the time getting where they need to go. Article, \"Paris bans driving due to smog,\" by Robert Duffer says, how Paris, after days of nearrecord pollution, enforced a partial driving ban to clear the air of the global city. It also says, how on Monday, motorist with evennumbered license plates were ordered to leave their cars at home or be fined a 22euro fine 31. The same order would be applied to oddnumbered plates the following day. Cars are the reason for polluting entire cities like Paris. This shows how bad cars can be because, of all the pollution that they can cause to an entire city.\n\nLikewise, in the article, \"Carfree day is spinning into a big hit in Bogota,\" by Andrew Selsky says, how programs that's set to spread to other countries, millions of Columbians hiked, biked, skated, or took the bus to work during a carfree day, leaving streets of this capital city eerily devoid of traffic jams. It was the third straight year cars have been banned with only buses and taxis permitted for the Day Without Cars in the capital city of 7 million. People like the idea of having carfree days because, it allows them to lesson the pollution that cars put out of their exhaust from people driving all the time. The article also tells how parks and sports centers have bustled throughout the city uneven, pitted sidewalks have been replaced by broad, smooth sidewalks rushhour restrictions have dramatically cut traffic and new restaurants and upscale shopping districts have cropped up. Having no cars has been good for the country of Columbia because, it has aloud them to repair things that have needed repairs for a long time, traffic jams have gone down, and restaurants and shopping districts have popped up, all due to the fact of having less cars around.\n\nIn conclusion, the use of less cars and having carfree days, have had a big impact on the environment of cities because, it is cutting down the air pollution that the cars have majorly polluted, it has aloud countries like Columbia to repair sidewalks, and cut down traffic jams. Limiting the use of cars would be a good thing for America. So we should limit the use of cars by maybe riding a bike, or maybe walking somewhere that isn't that far from you and doesn't need the use of a car to get you there. To me, limiting the use of cars might be a good thing to do.",
         "0"
        ],
        [
         "1",
         "005db917",
         "0",
         "Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, and other means of transportation make going from place to place easier and faster. However there's always a negative pollution. Although mobile transportation are a huge part of daily lives, we are endangering the Earth with harmful greenhouse gases, which could be suppressed.\n\nA small suburb community in Germany called Vauban, has started a \"carfree\" lifestyle. In this city, markets and stores are placed nearby homes, instead of being located by farend highways. Although Vauban is not completely carfree, 70% of Vauban families do not own cars Even a large 57% of families stated to have sold their cars to move to Vauban. Some families have even said to be less stressed depending on car transportation. Cars are responsible for about 12% of greenhouse gases, and can even be up to 50% in some carintensive areas in the United States.\n\nAnother insight to reduced car zones brings Paris' incident with smog. Paris' officials created a system that would in fact lower smog rates. On Monday, the motorists with evennumbered license plates numbers would be ordered to leave their cars at home, or they would suffer a fine. Same rule would occur on Tuesday, except motorists with oddnumbered license plates were targeted with fines. Congestion, or traffic, was reduced by 60% after five days of intense smog. Diesel fuel played a huge part in this pollution, having the fact that 67% of vehicles in France are of Diesel fuel. The impact of the clearing of smog, resided in banning the Tuesday rule of odd license plates.\n\nCould you imagine a day without seeing a single car being used? This phenomenon occurs once a year in Bogota, Colombia. With the exception of buses and taxis being used, cars are to be left unattended for an entire day. Having a carfree day just once a year can even reduce the pollution slightly. The day without cars is part of a campaign that originated in Bogota in the mid 1990s. This campaign has renewed and constructed numerous bicycle paths and sidewalks all over the city. Parks and sports centers have also sprung from this campaign. Devoting your time to a carfree lifestyle has it's hassles, but in hindsight, it has it's benefits.\n\nTo conclude, living a carfree lifestyle does not seem like a possibility in this day and age, however managing the use of cars and pollution is something every country should take time investing in. Think about how much of an impact it would be if everywhere worldwide would take part in airpollution reduction. Mobile transportation is lifestyle in a sense, and being dependent on cars or other means of transportation can impact the health of the Earth and even ourselves.",
         "0"
        ],
        [
         "2",
         "008f63e3",
         "0",
         "\"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To understand rosenthal's perspective, it is easier to suggest that America's car usage is decreasing slowly. This isn't necessarily bad in the sense that it has certain positive effects. The advantages of limiting car usage includes an increase in security and health, along with a decrease in pollution and dependence.\n\nFirstly, when car usage is limited security and health is more likely to be guaranteed. The feeling of being secure is highly important to individuals everywhere. For example, many people in colombia used public transportation during a car free day \"leaving the streets of this capital city \", according to Andrew Selsky, \"eerily devoid of traffic jams\". The complications that stem from traffic jams end with a feeling of confidence. The plan to get from point A to B was more simple just a second ago. This complication in your personal plans leads you to become stressed as a feeling of doubt overcomes all thoughts. If car usage was limited, there would be a control on how much traffic accumulates thus minimizing chance of stress. As Heidrun Walter states \"when i had a car i was always tense. I'm much happier this way\". not only does car usage minimize conditions detrimental to health, it also enlarges your capacity for exercise. The main purpose of the car is to get someone from one place to another. when an important job takes over your personal life, it becomes difficult to do things most enjoyed in life. limits on car usage forces you to stay in shape. According to Andrew Selsky \"parks and sports centers also have bloomed throughout the city\". Less cars means healthier and natural situations. With parks and sport centers becoming more efficient, it becomes easier to find a more physically active population. Overall, less usage on cars minimizes stress and increases health.\n\nSecondly, limting car usage becomes beneficial to the environment. Now a days people have become annoyed with others who care so passionately about the environment. If you look behind their constant cries for action, there are solid facts. Yespollution is bad for the environment. Yes a bad envorment means unhealthy living. Yes cars are one of the main contributors to pollution in the environment. A pattern of less car usage, as Elisabeth Rosenthal states \"will have beneficial implications for carbon emissions and the environment\". The less use of cars, the less pollution in the environment. One must observe limiting car usage as an opportunity to create a cleaner world and better future. The effects of pollution in the environment is completley dangerous and we, the car users, are to blame.\n\nAdditionally, it would lower the dependence on cars. Many people today find that their car is so useful. While it has many features and is a form of transportation, many do not figure what they would do if they did not have such a possesion. The development of people and their interaction with technology has left a wide gap between historic, natural ways and what is thought of as modern society. Being dependent is not always good for individuals. As david goldberg says \"all our development since world war II has been centered on the car, and that will have to change\". Many people could disagree and wonder why it is necessary to change our ways especially if we are so highly devloped. If being developed means being dependent on a harmful machine, then it could not be effective devlopment. According to Elisabeth Rosenthal \"cashstrapped americans could not afford new cars, and the unemployed were't going to work anyway\". Many people can't have the precious luxury of private transportation in the first place. Those who have had it have become distant to a more natural society. Peope have become so use to having cars that they have become oblivious to the significant effects. With limits on car usage , these effcts could be controlled.\n\nTo conclude, the advantages of limiting car usage is an increase in health, along with a decrease in pollution, and less dependence on cars. limiting car usage is a positive way to enfore an organized and clean environment, and ensure health and security of those who live in it. This is one reason America can be reffered to as a succesful country. It is not that America has decreased use of vehicles, but the fact that they have done what is best for majority.",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  \\\n",
       "0  0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1  005db917          0  Transportation is a large necessity in most co...   \n",
       "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "\n",
       "   generated  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Exemples (test) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d776d593-df8d-4df7-bf82-0fdef4661867",
       "rows": [
        [
         "0",
         "0000aaaa",
         "2",
         "Aaa bbb ccc."
        ],
        [
         "1",
         "1111bbbb",
         "3",
         "Bbb ccc ddd."
        ],
        [
         "2",
         "2222cccc",
         "4",
         "CCC ddd eee."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaa bbb ccc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>3</td>\n",
       "      <td>Bbb ccc ddd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>4</td>\n",
       "      <td>CCC ddd eee.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id          text\n",
       "0  0000aaaa          2  Aaa bbb ccc.\n",
       "1  1111bbbb          3  Bbb ccc ddd.\n",
       "2  2222cccc          4  CCC ddd eee."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Exemples (prompts) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prompt_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "instructions",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "98d42176-d380-41d8-aceb-df8015a81ab9",
       "rows": [
        [
         "0",
         "0",
         "Car-free cities",
         "Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.",
         "# In German Suburb, Life Goes On Without Cars by Elisabeth Rosenthal\n\n1 VAUBAN, Germany‚ÄîResidents of this upscale community are suburban pioneers, going where few soccer moms or commuting executives have ever gone before: they have given up their cars.\n\n2 Street parking, driveways and home garages are generally forbidden in this experimental new district on the outskirts of Freiburg, near the French and Swiss borders. Vauban‚Äôs streets are completely ‚Äúcar-free‚Äù‚Äîexcept the main thoroughfare, where the tram to downtown Freiburg runs, and a few streets on one edge of the community. Car ownership is allowed, but there are only two places to park‚Äîlarge garages at the edge of the development, where a car-owner buys a space, for $40,000, along with a home.\n\n3 As a result, 70 percent of Vauban‚Äôs families do not own cars, and 57 percent sold a car to move here. ‚ÄúWhen I had a car I was always tense. I‚Äôm much happier this way,‚Äù said Heidrun Walter, a media trainer and mother of two, as she walked verdant streets where the swish of bicycles and the chatter of wandering children drown out the occasional distant motor.\n\n4 Vauban, completed in 2006, is an example of a growing trend in Europe, the United States and elsewhere to separate suburban life from auto use, as a component of a movement called ‚Äúsmart planning.‚Äù\n\n5 Automobiles are the linchpin of suburbs, where middle-class families from Chicago to Shanghai tend to make their homes. And that, experts say, is a huge impediment to current efforts to drastically reduce greenhouse gas emissions from tailpipes . . . . Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe . . . and up to 50 percent in some car-intensive areas in the United States.\n\n6 While there have been efforts in the past two decades to make cities denser, and better for walking, planners are now taking the concept to the suburbs . . . . Vauban, home to 5,500 residents within a rectangular square mile, may be the most advanced experiment in low-car suburban life. But its basic precepts are being adopted around the world in attempts to make suburbs more compact and more accessible to public transportation, with less space for parking. In this new approach, stores are placed a walk away, on a main street, rather than in malls along some distant highway.\n\n7 ‚ÄúAll of our development since World War II has been centered on the car, and that will have to change,‚Äù said David Goldberg, an official of Transportation for America, a fast-growing coalition of hundreds of groups in the United States . . . who are promoting new communities that are less dependent on cars. Mr. Goldberg added: ‚ÄúHow much you drive is as important as whether you have a hybrid.‚Äù\n\n8 Levittown and Scarsdale, New York suburbs with spread-out homes and private garages, were the dream towns of the 1950s and still exert a strong appeal. But some new suburbs may well look more Vauban-like, not only in developed countries but also in the developing world, where emissions from an increasing number of private cars owned by the burgeoning middle class are choking cities.\n\n9 In the United States, the Environmental Protection Agency is promoting ‚Äúcar reduced‚Äù communities, and legislators are starting to act, if cautiously. Many experts expect public transport serving suburbs to play a much larger role in a new six-year federal transportation bill to be approved this year, Mr. Goldberg said. In previous bills, 80 percent of appropriations have by law gone to highways and only 20 percent to other transport. \n\nExcerpt from ‚ÄúIn German Suburb, Life Goes On Without Cars‚Äù by Elisabeth Rosenthal, from the New York Times. Copyright ¬© 2009 by the New York Times Company. Reprinted by permission of the New York Times Company via Copyright Clearance Center.\n\n# Paris bans driving due to smog by Robert Duffer\n\n10 After days of near-record pollution, Paris enforced a partial driving ban to clear the air of the global city.\n\n11 On Monday motorists with even-numbered license plates were ordered to leave their cars at home or suffer a 22-euro fine ($31). The same would apply to odd-numbered plates the following day.\n\n12 Almost 4,000 drivers were fined, according to Reuters1 . . . [Twenty-seven] people had their cars impounded for their reaction to the fine.\n\n13 That‚Äôs easier to imagine than a car-free Champs-Elysees.2\n\n14 Congestion 3 was down 60 percent in the capital of France, after five-days of intensifying smog . . . [The smog] rivaled Beijing, China, which is known as one of the most polluted cities in the world.\n\n15 Cold nights and warm days caused the warmer layer of air to trap car emissions.\n\n16 Diesel fuel was blamed, since France has . . . [a] tax policy that favors diesel over gasoline. Diesels make up 67 percent of vehicles in France, compared to a 53.3 percent average of diesel engines in the rest of Western Europe, according to Reuters.\n\n17 Paris typically has more smog than other European capitals . . . [Last] week Paris had 147 micrograms of particulate matter (PM) per cubic meter compared with 114 in Brussels and 79.7 in London, Reuters found.\n\n18 Delivery companies complained of lost revenue, while exceptions were made for plug-in cars, hybrids, and cars carrying three or more passengers. Public transit was free of charge from Friday to Monday, according to the BBC.\n\n19 The smog cleared enough Monday for the ruling French party to rescind the ban for oddnumbered plates on Tuesday. 1\n\nExcerpt from ‚ÄúParis bans driving due to smog‚Äù by Robert Duffer, from the Chicago Tribune. Copyright ¬© 2014 by the Chicago Tribune. Reprinted by permission of the Chicago Tribune via Copyright Clearance Center.\n\n# Car-free day is spinning into a big hit in Bogota by Andrew Selsky\n\nBOGOTA, Colombia‚ÄîIn a program that‚Äôs set to spread to other countries, millions of Colombians hiked, biked, skated or took buses to work during a car-free day yesterday, leaving the streets of this capital city eerily devoid of traffic jams.\n\n21 It was the third straight year cars have been banned with only buses and taxis permitted for the Day Without Cars in this capital city of 7 million. The goal is to promote alternative transportation and reduce smog. Violators faced $25 fines.\n\n22 The turnout was large, despite gray clouds that dumped occasional rain showers on Bogota.\n\n23 ‚ÄúThe rain hasn‚Äôt stopped people from participating,‚Äù said Bogota Mayor Antanas Mockus . . . .\n\n24 ‚ÄúIt‚Äôs a good opportunity to take away stress and lower air pollution,‚Äù said businessman Carlos Arturo Plaza as he rode a two-seat bicycle with his wife.\n\n25 For the first time, two other Colombian cities, Cali and Valledupar, joined the event.\n\n26 Municipal authorities from other countries came to Bogota to see the event and were enthusiastic. ‚ÄúThese people are generating a revolutionary change, and this is crossing borders,‚Äù said Enrique Riera, the mayor of Asunci√≥n, Paraguay. . . .\n\n27 The day without cars is part of an improvement campaign that began in Bogota in the mid1990s. It has seen the construction of 118 miles of bicycle paths, the most of any Latin American city, according to Mockus, the city‚Äôs mayor.\n\n28 Parks and sports centers also have bloomed throughout the city; uneven, pitted sidewalks have been replaced by broad, smooth sidewalks; rush-hour restrictions have dramatically cut traffic; and new restaurants and upscale shopping districts have cropped up.\n\nExcerpt from ‚ÄúCar-free day is spinning into a big hit in Bogota‚Äù by Andrew Selsky, from the Seattle Times. Copyright ¬© 2002 by the Seattle Times Company. Reprinted by permission of the Seattle Times Company via Copyright Clearance Center.\n\n# The End of Car Culture by Elisabeth Rosenthal\n\n29 President Obama‚Äôs ambitious goals to curb the United States‚Äô greenhouse gas emissions, unveiled last week, will get a fortuitous assist from an incipient1 shift in American behavior: recent studies suggest that Americans are buying fewer cars, driving less and getting fewer licenses as each year goes by.\n\n30 That has left researchers pondering a fundamental question: Has America passed peak driving?\n\n31 The United States, with its broad expanses and suburban ideals, had long been one of the world‚Äôs prime car cultures. It is the birthplace of the Model T; the home of Detroit; the place where Wilson Pickett immortalized ‚ÄúMustang Sally‚Äù . . . .\n\n32 But America‚Äôs love affair with its vehicles seems to be cooling. When adjusted for population growth, the number of miles driven in the United States peaked in 2005 and dropped steadily thereafter, according to an analysis by Doug Short of Advisor Perspectives, an investment research company. As of April 2013, the number of miles driven per person was nearly 9 percent below the peak and equal to where the country was in January 1995. Part of the explanation certainly lies in the recession, because cash-strapped Americans could not afford new cars, and the unemployed weren‚Äôt going to work anyway. But by many measures the decrease in driving preceded the downturn and appears to be persisting now that recovery is under way. The next few years will be telling.\n\n33 ‚ÄúWhat most intrigues me is that rates of car ownership per household and per person started to come down two to three years before the downturn,‚Äù said Michael Sivak, who studies the trend and who is a research professor at the University of Michigan‚Äôs Transportation Research Institute. ‚ÄúI think that means something more fundamental is going on.‚Äù\n\n34 If the pattern persists‚Äîand many sociologists believe it will‚Äîit will have beneficial implications for carbon emissions and the environment, since transportation is the second largest source of America‚Äôs emissions, just behind power plants. But it could have negative implications for the car industry. Indeed, companies like Ford and Mercedes are already rebranding themselves ‚Äúmobility‚Äù companies with a broader product range beyond the personal vehicle.\n\n35 ‚ÄúDifferent things are converging which suggest that we are witnessing a long-term cultural shift,‚Äù said Mimi Sheller, a sociology professor at Drexel University and director of its Mobilities Research and Policy Center. She cites various factors: the Internet makes telecommuting possible and allows people to feel more connected without driving to meet friends. The renewal of center cities has made the suburbs less appealing and has drawn empty nesters back in. Likewise the rise in cellphones and car-pooling apps has facilitated more flexible commuting arrangements, including the evolution of shared van services for getting to work.\n\n36 With all these changes, people who stopped car commuting as a result of the recession may find less reason to resume the habit. . . .\n\n37 New York‚Äôs new bike-sharing program and its skyrocketing bridge and tunnel tolls reflect those new priorities, as do a proliferation of car-sharing programs across the nation.\n\n38 Demographic shifts in the driving population suggest that the trend may accelerate. There has been a large drop in the percentage of 16- to 39-year-olds getting a license, while older people are likely to retain their licenses as they age, Mr. Sivak‚Äôs research has found.\n\n39 He and I have similar observations about our children. Mine (19 and 21) have not bothered to get a driver‚Äôs license, even though they both live in places where one could come in handy. They are interested, but it‚Äôs not a priority. They organize their summer jobs and social life around where they can walk or take public transportation or car-pool with friends.\n\n40 Mr. Sivak‚Äôs son lives in San Francisco and has a car but takes Bay Area Rapid Transit, when he can, even though that often takes longer than driving. ‚ÄúWhen I was in my 20s and 30s,‚Äù Mr. Sivak said, ‚ÄúI was curious about what kind of car people drove, but young people don‚Äôt really care. A car is just a means of getting from A to B when BART doesn‚Äôt work.‚Äù\n\n41 A study last year found that driving by young people decreased 23 percent between 2001 and 2009. . . .\n\n42 Whether members of the millennial generation will start buying more cars once they have kids to take to soccer practice and school plays remains an open question. But such projections have important business implications, even if car buyers are merely older or buying fewer cars in a lifetime rather than rejecting car culture outright.\n\n43 At the Mobile World Congress last year in Barcelona, Spain, Bill Ford, executive chairman of the Ford Motor Company, laid out a business plan for a world in which personal vehicle ownership is impractical or undesirable. He proposed partnering with the telecommunications industry to create cities in which ‚Äúpedestrian, bicycle, private cars, commercial and public transportation traffic are woven into a connected network to save time, conserve resources, lower emissions and improve safety.‚Äù\n\nExcerpt from ‚ÄúThe End of Car Culture‚Äù by Elisabeth Rosenthal, from the New York Times. Copyright ¬© 2013 by the New York Times Company. Reprinted by permission of the New York Times Company via Copyright Clearance Center.\n"
        ],
        [
         "1",
         "1",
         "Does the electoral college work?",
         "Write a letter to your state senator in which you argue in favor of keeping the Electoral College or changing to election by popular vote for the president of the United States. Use the information from the texts in your essay. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to include a claim; address counterclaims; use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your response in the space provided.",
         "# What Is the Electoral College? by the Office of the Federal Register\n\n1 The Electoral College is a process, not a place. The founding fathers established it in the Constitution as a compromise between election of the President by a vote in Congress and election of the President by a popular vote of qualified citizens.\n\n2 The Electoral College process consists of the selection of the electors, the meeting of the electors where they vote for President and Vice President, and the counting of the electoral votes by Congress.\n\n3 The Electoral College consists of 538 electors. A majority of 270 electoral votes is required to elect the President. Your state‚Äôs entitled allotment of electors equals the number of members in its Congressional delegation: one for each member in the House of Representatives plus two for your Senators. . . .\n\n4 Under the 23rd Amendment of the Constitution, the District of Columbia is allocated 3 electors and treated like a state for purposes of the Electoral College. For this reason, in the following discussion, the word ‚Äústate‚Äù also refers to the District of Columbia.\n\n5 Each candidate running for President in your state has his or her own group of electors. The electors are generally chosen by the candidate‚Äôs political party, but state laws vary on how the electors are selected and what their responsibilities are. . . .\n\n6 The presidential election is held every four years on the Tuesday after the first Monday in November. You help choose your state‚Äôs electors when you vote for President because when you vote for your candidate you are actually voting for your candidate‚Äôs electors.\n\n7 Most states have a ‚Äúwinner-take-all‚Äù system that awards all electors to the winning presidential candidate. However, Maine and Nebraska each have a variation of ‚Äúproportional representation.‚Äù . . .\n\n8 After the presidential election, your governor prepares a ‚ÄúCertificate of Ascertainment‚Äù listing all of the candidates who ran for President in your state along with the names of their respective electors. The Certificate of Ascertainment also declares the winning presidential candidate in your state and shows which electors will represent your state at the meeting of the electors in December of the election year. Your state‚Äôs Certificates of Ascertainments are sent to the Congress and the National Archives as part of the official records of the presidential election.\n\n# The Indefensible Electoral College: Why even the best-laid defenses of the system are wrong by Bradford Plumer\n\n9 What have Richard Nixon, Jimmy Carter, Bob Dole, the U.S. Chamber of Commerce, and the AFL-CIO all, in their time, agreed on? Answer: Abolishing the electoral college! They‚Äôre not alone; according to a Gallup poll in 2000, taken shortly after Al Gore‚Äîthanks to the quirks of the electoral college‚Äîwon the popular vote but lost the presidency,1 over 60 percent of voters would prefer a direct election to the kind we have now. This year voters can expect another close election in which the popular vote winner could again lose the presidency. And yet, the electoral college still has its defenders. What gives? . . . What‚Äôs wrong with the electoral college\n\n10 Under the electoral college system, voters vote not for the president, but for a slate of electors, who in turn elect the president. If you lived in Texas, for instance, and wanted to vote for John Kerry, you‚Äôd vote for a slate of 34 Democratic electors pledged to Kerry. On the offchance that those electors won the statewide election, they would go to Congress and Kerry would get 34 electoral votes. Who are the electors? They can be anyone not holding public office. Who picks the electors in the first place? It depends on the state. Sometimes state conventions, sometimes the state party‚Äôs central committee, sometimes the presidential candidates themselves. Can voters control whom their electors vote for? Not always. Do voters sometimes get confused about the electors and vote for the wrong candidate? Sometimes.\n\n11 The single best argument against the electoral college is what we might call the disaster factor. The American people should consider themselves lucky that the 2000 fiasco was the biggest election crisis in a century; the system allows for much worse. Consider that state legislatures are technically responsible for picking electors, and that those electors could always defy the will of the people. Back in 1960, segregationists in the Louisiana legislature nearly succeeded in replacing the Democratic electors with new electors who would oppose John F. Kennedy. (So that a popular vote for Kennedy would not have actually gone to Kennedy.) In the same vein, ‚Äúfaithless‚Äù electors have occasionally refused to vote for their party‚Äôs candidate and cast a deciding vote for whomever they please. . . . Oh, and what if a state sends two slates of electors to Congress? It happened in Hawaii in 1960. Luckily, Vice President Richard Nixon, who was presiding over the Senate, validated only his opponent‚Äôs electors, but he made sure to do so ‚Äúwithout establishing a precedent.‚Äù What if it happened again?\n\n12 Perhaps most worrying is the prospect of a tie in the electoral vote. In that case, the election would be thrown to the House of Representatives, where state delegations vote on the president. (The Senate would choose the vice-president.) Because each state casts only one vote, the single representative from Wyoming, representing 500,000 voters, would have as much say as the 55 representatives from California, who represent 35 million voters. Given that many voters vote one party for president and another for Congress, the House‚Äôs selection can hardly be expected to reflect the will of the people. And if an electoral tie seems unlikely, consider this: In 1968, a shift of just 41,971 votes would have deadlocked the election; In 1976, a tie would have occurred if a mere 5,559 voters in Ohio and 3,687 voters in Hawaii had voted the other way. The election is only a few swing voters away from catastrophe.\n\n13 At the most basic level, the electoral college is unfair to voters. Because of the winner-takeall system in each state, candidates don't spend time in states they know they have no chance of winning, focusing only on the tight races in the ‚Äúswing‚Äù states. During the 2000 campaign, seventeen states didn‚Äôt see the candidates at all, including Rhode Island and South Carolina, and voters in 25 of the largest media markets didn‚Äôt get to see a single campaign ad. If anyone has a good argument for putting the fate of the presidency in the hands of a few swing voters in Ohio, they have yet to make it. . . .\n\n14 It‚Äôs official: The electoral college is unfair, outdated, and irrational. The best arguments in favor of it are mostly assertions without much basis in reality. And the arguments against direct elections are spurious at best. It‚Äôs hard to say this, but Bob Dole was right: Abolish the electoral college!\n\n# In Defense of the Electoral College: Five reasons to keep our despised method of choosing the President by Judge Richard A. Posner\n\n15 The Electoral College is widely regarded as an anachronism,1 a non-democratic method of selecting a president that ought to be overruled by declaring the candidate who receives the most popular votes the winner. The advocates of this position are correct in arguing that the Electoral College method is not democratic in a modern sense . . . it is the electors who elect the president, not the people. When you vote for a presidential candidate you‚Äôre actually voting for a slate of electors.\n\n16 But each party selects a slate of electors trusted to vote for the party‚Äôs nominee (and that trust is rarely betrayed) . . . however, it is entirely possible that the winner of the electoral vote will not win the national popular vote. Yet that has happened very rarely. It happened in 2000, when Gore had more popular votes than Bush yet fewer electoral votes, but that was the first time since 1888.\n\n17 There are five reasons for retaining the Electoral College despite its lack of democratic pedigree;2 all are practical reasons, not liberal or conservative3 reasons.\n\n## 1) Certainty of Outcome\n\n18 A dispute over the outcome of an Electoral College vote is possible‚Äî--it happened in 2000--‚Äîbut it‚Äôs less likely than a dispute over the popular vote. The reason is that the winning candidate‚Äôs share of the Electoral College invariably exceeds his share of the popular vote. In 2012‚Äôs election, for example, Obama4 received 61.7 percent of the electoral vote compared to only 51.3 percent of the popular votes cast for him and Romney.5 . . . Because almost all states award electoral votes on a winner-take-all basis, even a very slight plurality6 in a state creates a landslide electoral-vote victory in that state. A tie in the nationwide electoral vote is possible because the total number of votes‚Äî--538‚Äî--is an even number, but it is highly unlikely. . . .\n\n## 2) Everyone‚Äôs President\n\n19 The Electoral College requires a presidential candidate to have trans-regional appeal. No region (South, Northeast, etc.) has enough electoral votes to elect a president. So a solid regional favorite, such as Romney was in the South, has no incentive to campaign heavily in those states, for he gains no electoral votes by increasing his plurality in states that he knows he will win. This is a desirable result because a candidate with only regional appeal is unlikely to be a successful president. The residents of the other regions are likely to feel disenfranchised‚Äîto feel that their votes do not count, that the new president will have no regard for their interests, that he really isn‚Äôt their president.\n\n## 3) Swing States\n\n20 The winner-take-all method of awarding electoral votes induces the candidates‚Äîas we saw in 2012‚Äôs election‚Äîto focus their campaign efforts on the toss-up states . . . . Voters in toss-up states are more likely to pay close attention to the campaign‚Äîto really listen to the competing candidates‚Äîknowing that they are going to decide the election. They are likely to be the most thoughtful voters, on average (and for the further reason that they will have received the most information and attention from the candidates), and the most thoughtful voters should be the ones to decide the election.\n\n## 4) Big States\n\n21 The Electoral College restores some of the weight in the political balance that large states (by population) lose by virtue of the mal-apportionment of the Senate decreed in the Constitution. . . . The popular vote was very close in Florida in 2012; nevertheless Obama, who won that vote, got 29 electoral votes. A victory by the same margin in Wyoming would net the winner only 3 electoral votes. So, other things being equal, a large state gets more attention from presidential candidates in a campaign than a small state does. . . .\n\n## 5) Avoid Run-Off Elections\n\n22 The Electoral College avoids the problem of elections in which no candidate receives a majority of the votes cast. For example, Nixon in 1968 and Clinton in 1992 both had only a 43 percent plurality of the popular votes, while winning a majority in the Electoral College (301 and 370 electoral votes, respectively). There is pressure for run-off elections when no candidate wins a majority of the votes cast; that pressure, which would greatly complicate the presidential election process, is reduced by the Electoral College, which invariably produces a clear winner. . . .\n\n23 It can be argued that the Electoral College method of selecting the president may turn off potential voters for a candidate who has no hope of carrying their state‚ÄîDemocrats in Texas, for example, or Republicans in California. Knowing their vote will have no effect, they have less incentive to pay attention to the campaign than they would have if the president were picked by popular vote . . . . But of course no voter‚Äôs vote swings a national election, and in spite of that, about one-half the eligible American population did vote in 2012‚Äôs election. Voters in presidential elections are people who want to express a political preference rather than people who think that a single vote may decide an election. . . .\n"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                       prompt_name  \\\n",
       "0          0                   Car-free cities   \n",
       "1          1  Does the electoral college work?   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Write an explanatory essay to inform fellow ci...   \n",
       "1  Write a letter to your state senator in which ...   \n",
       "\n",
       "                                         source_text  \n",
       "0  # In German Suburb, Life Goes On Without Cars ...  \n",
       "1  # What Is the Electoral College? by the Office...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Exemple de texte avec prompt associ√© :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prompt_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prompt_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "instructions",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "344ef9d2-73bb-47df-bb71-e5b808a07877",
       "rows": [
        [
         "0",
         "0",
         "Car-free cities",
         "Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.",
         "Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and built the first ModelT. Cars have played a major role in our every day lives since then. But now, people are starting to question if limiting car usage would be a good thing. To me, limiting the use of cars might be a good thing to do.\n\nIn like matter of this, article, \"In German Suburb, Life Goes On Without Cars,\" by Elizabeth Rosenthal states, how automobiles are the linchpin of suburbs, where middle class families from either Shanghai or Chicago tend to make their homes. Experts say how this is a huge impediment to current efforts to reduce greenhouse gas emissions from tailpipe. Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe...and up to 50 percent in some carintensive areas in the United States. Cars are the main reason for the greenhouse gas emissions because of a lot of people driving them around all the time getting where they need to go. Article, \"Paris bans driving due to smog,\" by Robert Duffer says, how Paris, after days of nearrecord pollution, enforced a partial driving ban to clear the air of the global city. It also says, how on Monday, motorist with evennumbered license plates were ordered to leave their cars at home or be fined a 22euro fine 31. The same order would be applied to oddnumbered plates the following day. Cars are the reason for polluting entire cities like Paris. This shows how bad cars can be because, of all the pollution that they can cause to an entire city.\n\nLikewise, in the article, \"Carfree day is spinning into a big hit in Bogota,\" by Andrew Selsky says, how programs that's set to spread to other countries, millions of Columbians hiked, biked, skated, or took the bus to work during a carfree day, leaving streets of this capital city eerily devoid of traffic jams. It was the third straight year cars have been banned with only buses and taxis permitted for the Day Without Cars in the capital city of 7 million. People like the idea of having carfree days because, it allows them to lesson the pollution that cars put out of their exhaust from people driving all the time. The article also tells how parks and sports centers have bustled throughout the city uneven, pitted sidewalks have been replaced by broad, smooth sidewalks rushhour restrictions have dramatically cut traffic and new restaurants and upscale shopping districts have cropped up. Having no cars has been good for the country of Columbia because, it has aloud them to repair things that have needed repairs for a long time, traffic jams have gone down, and restaurants and shopping districts have popped up, all due to the fact of having less cars around.\n\nIn conclusion, the use of less cars and having carfree days, have had a big impact on the environment of cities because, it is cutting down the air pollution that the cars have majorly polluted, it has aloud countries like Columbia to repair sidewalks, and cut down traffic jams. Limiting the use of cars would be a good thing for America. So we should limit the use of cars by maybe riding a bike, or maybe walking somewhere that isn't that far from you and doesn't need the use of a car to get you there. To me, limiting the use of cars might be a good thing to do."
        ],
        [
         "1",
         "0",
         "Car-free cities",
         "Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.",
         "Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, and other means of transportation make going from place to place easier and faster. However there's always a negative pollution. Although mobile transportation are a huge part of daily lives, we are endangering the Earth with harmful greenhouse gases, which could be suppressed.\n\nA small suburb community in Germany called Vauban, has started a \"carfree\" lifestyle. In this city, markets and stores are placed nearby homes, instead of being located by farend highways. Although Vauban is not completely carfree, 70% of Vauban families do not own cars Even a large 57% of families stated to have sold their cars to move to Vauban. Some families have even said to be less stressed depending on car transportation. Cars are responsible for about 12% of greenhouse gases, and can even be up to 50% in some carintensive areas in the United States.\n\nAnother insight to reduced car zones brings Paris' incident with smog. Paris' officials created a system that would in fact lower smog rates. On Monday, the motorists with evennumbered license plates numbers would be ordered to leave their cars at home, or they would suffer a fine. Same rule would occur on Tuesday, except motorists with oddnumbered license plates were targeted with fines. Congestion, or traffic, was reduced by 60% after five days of intense smog. Diesel fuel played a huge part in this pollution, having the fact that 67% of vehicles in France are of Diesel fuel. The impact of the clearing of smog, resided in banning the Tuesday rule of odd license plates.\n\nCould you imagine a day without seeing a single car being used? This phenomenon occurs once a year in Bogota, Colombia. With the exception of buses and taxis being used, cars are to be left unattended for an entire day. Having a carfree day just once a year can even reduce the pollution slightly. The day without cars is part of a campaign that originated in Bogota in the mid 1990s. This campaign has renewed and constructed numerous bicycle paths and sidewalks all over the city. Parks and sports centers have also sprung from this campaign. Devoting your time to a carfree lifestyle has it's hassles, but in hindsight, it has it's benefits.\n\nTo conclude, living a carfree lifestyle does not seem like a possibility in this day and age, however managing the use of cars and pollution is something every country should take time investing in. Think about how much of an impact it would be if everywhere worldwide would take part in airpollution reduction. Mobile transportation is lifestyle in a sense, and being dependent on cars or other means of transportation can impact the health of the Earth and even ourselves."
        ],
        [
         "2",
         "0",
         "Car-free cities",
         "Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.",
         "\"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To understand rosenthal's perspective, it is easier to suggest that America's car usage is decreasing slowly. This isn't necessarily bad in the sense that it has certain positive effects. The advantages of limiting car usage includes an increase in security and health, along with a decrease in pollution and dependence.\n\nFirstly, when car usage is limited security and health is more likely to be guaranteed. The feeling of being secure is highly important to individuals everywhere. For example, many people in colombia used public transportation during a car free day \"leaving the streets of this capital city \", according to Andrew Selsky, \"eerily devoid of traffic jams\". The complications that stem from traffic jams end with a feeling of confidence. The plan to get from point A to B was more simple just a second ago. This complication in your personal plans leads you to become stressed as a feeling of doubt overcomes all thoughts. If car usage was limited, there would be a control on how much traffic accumulates thus minimizing chance of stress. As Heidrun Walter states \"when i had a car i was always tense. I'm much happier this way\". not only does car usage minimize conditions detrimental to health, it also enlarges your capacity for exercise. The main purpose of the car is to get someone from one place to another. when an important job takes over your personal life, it becomes difficult to do things most enjoyed in life. limits on car usage forces you to stay in shape. According to Andrew Selsky \"parks and sports centers also have bloomed throughout the city\". Less cars means healthier and natural situations. With parks and sport centers becoming more efficient, it becomes easier to find a more physically active population. Overall, less usage on cars minimizes stress and increases health.\n\nSecondly, limting car usage becomes beneficial to the environment. Now a days people have become annoyed with others who care so passionately about the environment. If you look behind their constant cries for action, there are solid facts. Yespollution is bad for the environment. Yes a bad envorment means unhealthy living. Yes cars are one of the main contributors to pollution in the environment. A pattern of less car usage, as Elisabeth Rosenthal states \"will have beneficial implications for carbon emissions and the environment\". The less use of cars, the less pollution in the environment. One must observe limiting car usage as an opportunity to create a cleaner world and better future. The effects of pollution in the environment is completley dangerous and we, the car users, are to blame.\n\nAdditionally, it would lower the dependence on cars. Many people today find that their car is so useful. While it has many features and is a form of transportation, many do not figure what they would do if they did not have such a possesion. The development of people and their interaction with technology has left a wide gap between historic, natural ways and what is thought of as modern society. Being dependent is not always good for individuals. As david goldberg says \"all our development since world war II has been centered on the car, and that will have to change\". Many people could disagree and wonder why it is necessary to change our ways especially if we are so highly devloped. If being developed means being dependent on a harmful machine, then it could not be effective devlopment. According to Elisabeth Rosenthal \"cashstrapped americans could not afford new cars, and the unemployed were't going to work anyway\". Many people can't have the precious luxury of private transportation in the first place. Those who have had it have become distant to a more natural society. Peope have become so use to having cars that they have become oblivious to the significant effects. With limits on car usage , these effcts could be controlled.\n\nTo conclude, the advantages of limiting car usage is an increase in health, along with a decrease in pollution, and less dependence on cars. limiting car usage is a positive way to enfore an organized and clean environment, and ensure health and security of those who live in it. This is one reason America can be reffered to as a succesful country. It is not that America has decreased use of vehicles, but the fact that they have done what is best for majority."
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id      prompt_name  \\\n",
       "0          0  Car-free cities   \n",
       "1          0  Car-free cities   \n",
       "2          0  Car-free cities   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Write an explanatory essay to inform fellow ci...   \n",
       "1  Write an explanatory essay to inform fellow ci...   \n",
       "2  Write an explanatory essay to inform fellow ci...   \n",
       "\n",
       "                                                text  \n",
       "0  Cars. Cars have been around since they became ...  \n",
       "1  Transportation is a large necessity in most co...  \n",
       "2  \"America's love affair with it's vehicles seem...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## √âtape 2 ‚Äî Chargement et exploration des donn√©es\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Chargement des fichiers\n",
    "TRAIN_PATH = \"data/train_essays.csv\"\n",
    "TEST_PATH = \"data/test_essays.csv\"\n",
    "PROMPT_PATH = \"data/train_prompts.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "prompt_df = pd.read_csv(PROMPT_PATH)\n",
    "\n",
    "# --- Dimensions des datasets\n",
    "print(\"üî¢ Dimensions :\")\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test : {test_df.shape}\")\n",
    "print(f\"Prompts: {prompt_df.shape}\")\n",
    "\n",
    "# --- Types de colonnes\n",
    "print(\"\\nüß± Types de donn√©es (train):\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "# --- Valeurs manquantes\n",
    "print(\"\\n‚ùì Valeurs manquantes (train) :\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# --- Colonnes disponibles\n",
    "print(\"\\nüìå Colonnes disponibles :\")\n",
    "print(\"Train :\", train_df.columns.tolist())\n",
    "print(\"Test  :\", test_df.columns.tolist())\n",
    "print(\"Prompts :\", prompt_df.columns.tolist())\n",
    "\n",
    "# --- Aper√ßu\n",
    "print(\"\\nüìù Exemples (train) :\")\n",
    "display(train_df.head(3))\n",
    "\n",
    "print(\"\\nüìù Exemples (test) :\")\n",
    "display(test_df.head(3))\n",
    "\n",
    "print(\"\\nüìù Exemples (prompts) :\")\n",
    "display(prompt_df.head(3))\n",
    "\n",
    "# --- Distribution des classes\n",
    "if 'label' in train_df.columns:\n",
    "    print(\"\\nüìä Distribution des classes :\")\n",
    "    class_counts = train_df['label'].value_counts()\n",
    "    print(class_counts)\n",
    "\n",
    "    sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "    plt.title(\"Distribution des classes (label)\")\n",
    "    plt.xlabel(\"Classe (0 = humain, 1 = IA)\")\n",
    "    plt.ylabel(\"Nombre d'exemples\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Longueur des textes\n",
    "train_df['text_length'] = train_df['text'].apply(lambda x: len(str(x).split()))\n",
    "test_df['text_length'] = test_df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "plt.hist(train_df['text_length'], bins=50, alpha=0.7, label='train')\n",
    "plt.hist(test_df['text_length'], bins=50, alpha=0.7, label='test')\n",
    "plt.title(\"Distribution de la longueur des textes (en tokens)\")\n",
    "plt.xlabel(\"Nombre de mots\")\n",
    "plt.ylabel(\"Fr√©quence\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Prompts li√©s aux textes (si 'prompt_id' existe)\n",
    "if 'prompt_id' in train_df.columns and 'prompt_id' in prompt_df.columns:\n",
    "    merged_df = train_df.merge(prompt_df, on='prompt_id', how='left')\n",
    "    print(\"\\nüîó Exemple de texte avec prompt associ√© :\")\n",
    "    display(merged_df[['prompt_id', 'prompt_name', 'instructions', 'text']].head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80b208",
   "metadata": {},
   "source": [
    "###  **Structure des fichiers**\n",
    "\n",
    "* **`train_essays.csv`** : 1378 exemples avec labels (`generated` = 0/1).\n",
    "* **`test_essays.csv`** : 3 exemples sans labels.\n",
    "* **`train_prompts.csv`** : 2 prompts diff√©rents.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Colonnes cl√©s**\n",
    "\n",
    "* `train` : `id`, `promptid`, `text`, `generated`\n",
    "* `test` : `id`, `promptid`, `text`\n",
    "* `prompts` : `promptid`, `promptname`, `instructions`, `source_text`\n",
    "\n",
    "---\n",
    "\n",
    "###  **Longueur des textes**\n",
    "\n",
    "* Distribution centr√©e autour de **500‚Äì600 tokens**, max ‚âà 1300.\n",
    "* Uniformit√© entre `train` et `test` (visuellement, pas d‚Äô√©cart significatif).\n",
    "\n",
    "---\n",
    "\n",
    "###  **Qualit√©**\n",
    "\n",
    "* Aucune valeur manquante.\n",
    "* Types coh√©rents.\n",
    "* Donn√©es pr√™tes pour :\n",
    "\n",
    "  * fusion `essays + prompts` via `promptid`\n",
    "  * encodage (troncature n√©cessaire si mod√®le avec limite de tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f382efb",
   "metadata": {},
   "source": [
    "## √âtape 3 ‚Äî Chargement du tokenizer BERT et extraction des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb81c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Chargement du tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Chargement du mod√®le BERT sans classification head\n",
    "embedding_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "embedding_model.eval()  # Mode √©valuation (pas de dropout)\n",
    "\n",
    "# Utiliser le GPU si disponible\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_model.to(device)\n",
    "\n",
    "# Fonction d'encodage + embedding\n",
    "def get_bert_embedding(texts):\n",
    "    with torch.no_grad():\n",
    "        encoded = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        input_ids = encoded['input_ids'].to(device)\n",
    "        token_type_ids = encoded['token_type_ids'].to(device)\n",
    "        attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "        output = embedding_model(input_ids=input_ids,\n",
    "                                 token_type_ids=token_type_ids,\n",
    "                                 attention_mask=attention_mask)\n",
    "        \n",
    "        return output.last_hidden_state  # shape: (batch_size, seq_len, hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62a3a8",
   "metadata": {},
   "source": [
    "### Test r√©el et imm√©diat de la fonction get_bert_embedding sur un mini-batch extrait de train_df['text']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91675b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Textes d'entr√©e :\n",
      "\n",
      "--- Texte 1 (584 mots) ---\n",
      "Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and built the first ModelT. Cars have played a major role in our every day lives since then. But now, people are starting to question if limiting car usage would be a good thing. To me, limiting the use of car...\n",
      "\n",
      "--- Texte 2 (462 mots) ---\n",
      "Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, and other means of transportation make going from place to place easier and faster. However there's always a negative pollution. Although mobile transportation are a huge part of daily lives, we are endanger...\n",
      "\n",
      "--- Texte 3 (744 mots) ---\n",
      "\"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To understand rosenthal's perspective, it is easier to suggest that America's car usage is decreasing slowly. This isn't necessarily bad in the sense that it has certain positive effects. The advantages of limit...\n",
      "\n",
      " Forme de l'output (embedding BERT): torch.Size([3, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "# S√©lection de 3 textes depuis le jeu d'entra√Ænement\n",
    "sample_texts = train_df['text'].dropna().iloc[:3].tolist()\n",
    "\n",
    "# Affichage des textes bruts\n",
    "print(\"üìù Textes d'entr√©e :\\n\")\n",
    "for i, txt in enumerate(sample_texts):\n",
    "    print(f\"--- Texte {i+1} ({len(txt.split())} mots) ---\\n{txt[:300]}...\\n\")\n",
    "\n",
    "# R√©cup√©ration des embeddings\n",
    "embeddings = get_bert_embedding(sample_texts)\n",
    "\n",
    "# Infos sur la sortie\n",
    "print(\" Forme de l'output (embedding BERT):\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b3db9",
   "metadata": {},
   "source": [
    "###  **Entr√©e**\n",
    "\n",
    "* **3 textes** entre **462 et 744 mots**.\n",
    "* Sujet : **limitation de l‚Äôusage des voitures** (prompt 0).\n",
    "* Longueur conforme aux capacit√©s de BERT (512 tokens max).\n",
    "\n",
    "  * Troncature automatique a pu √™tre appliqu√©e.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Sortie (embeddings BERT)**\n",
    "\n",
    "* `torch.Size([3, 512, 768])`\n",
    "  ‚ü∂ 3 textes, chacun encod√© en **512 tokens** (post-troncature), chaque token repr√©sent√© par un vecteur **de dimension 768**.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Conclusion**\n",
    "\n",
    "Tout fonctionne comme pr√©vu :\n",
    "\n",
    "* Textes bien encod√©s.\n",
    "* Format exploitable pour :\n",
    "\n",
    "  * le Discriminateur\n",
    "  * la visualisation\n",
    "  * des m√©triques comme la similarit√© cosinus ou l‚ÄôAUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29e03b",
   "metadata": {},
   "source": [
    "## √âtape 4 ‚Äî Pr√©paration des donn√©es pour PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c075434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'prompt_id', 'text', 'generated', 'text_length']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2afe507",
   "metadata": {},
   "source": [
    "* **id** : identifiant unique du texte.\n",
    "* **prompt\\_id** : identifiant du sujet (r√©f√©rence √† `train_prompts.csv`).\n",
    "* **text** : contenu textuel (l'essai).\n",
    "* **generated** : `0` si humain, `1` si g√©n√©r√© par IA.\n",
    "* **text\\_length** : nombre de tokens ou mots (ajout√© ou calcul√©).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f36441a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train batches : 69\n",
      "‚úÖ Validation batches : 9\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Dataset PyTorch pour GAN\n",
    "class GANDAIGDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], float(self.labels[idx])\n",
    "\n",
    "# Split train/validation\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(train_df) * train_ratio)\n",
    "\n",
    "train_texts = train_df['text'].iloc[:train_size].tolist()\n",
    "train_labels = train_df['generated'].iloc[:train_size].tolist()\n",
    "\n",
    "val_texts = train_df['text'].iloc[train_size:].tolist()\n",
    "val_labels = train_df['generated'].iloc[train_size:].tolist()\n",
    "\n",
    "# Cr√©ation des datasets\n",
    "train_dataset = GANDAIGDataset(train_texts, train_labels)\n",
    "val_dataset = GANDAIGDataset(val_texts, val_labels)\n",
    "\n",
    "# Param√®tres\n",
    "train_batch_size = 16\n",
    "val_batch_size = 32\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Train batches : {len(train_loader)}\")\n",
    "print(f\"‚úÖ Validation batches : {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb9b048",
   "metadata": {},
   "source": [
    "*  **69 batches d'entra√Ænement** ‚Üí pour `train_loader`, √† raison de `batch_size=20` environ (1378 / 20 ‚âà 69).\n",
    "*  **9 batches de validation** ‚Üí si tu as fait un `split` autour de 90/10.\n",
    "\n",
    "Je peux maintenant :\n",
    "\n",
    "1. **Contr√¥ler la convergence du mod√®le** (loss D/G).\n",
    "2. **Calculer des m√©triques sur la validation** (AUC, accuracy).\n",
    "3. **Sauvegarder les mod√®les (`netG`, `netD`)** pour r√©utilisation :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824ee10",
   "metadata": {},
   "source": [
    "## √âtape 5 ‚Äî D√©finition du G√©n√©rateur (Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b8585e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEncoder\n",
    "\n",
    "# Configuration du BERTEncoder\n",
    "num_hidden_layers = 4\n",
    "bert_config = BertConfig(\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072\n",
    ")\n",
    "\n",
    "# D√©finition du g√©n√©rateur\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, seq_len=512, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, seq_len * hidden_size)\n",
    "        self.bert_encoder = BertEncoder(bert_config)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.fc(noise)                            # (B, seq_len * hidden)\n",
    "        x = x.view(-1, self.seq_len, self.hidden_size)\n",
    "        output = self.bert_encoder(inputs_embeds=x)\n",
    "        return output.last_hidden_state               # (B, seq_len, hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513fe4b",
   "metadata": {},
   "source": [
    "## √âtape 6 ‚Äî D√©finition du Discriminateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acd89206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers.models.bert.modeling_bert import BertEncoder\n",
    "\n",
    "# Pooling par moyenne sur les tokens\n",
    "class MeanBertPooler(nn.Module):\n",
    "    def forward(self, hidden_states):\n",
    "        return hidden_states.mean(dim=1)  # (batch_size, hidden_size)\n",
    "\n",
    "# Discriminateur bas√© sur BERTEncoder\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, pretrained_encoder, num_layers_to_keep=6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = pretrained_encoder.config\n",
    "\n",
    "        # Cr√©er un nouveau BertEncoder avec seulement les N premi√®res couches\n",
    "        self.bert_encoder = BertEncoder(self.config)\n",
    "        self.bert_encoder.layer = nn.ModuleList(\n",
    "            pretrained_encoder.encoder.layer[:num_layers_to_keep]\n",
    "        )\n",
    "\n",
    "        self.pooler = MeanBertPooler()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # sortie binaire\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x : embeddings BERT de taille (batch, seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        attention_mask = torch.ones(x.size()[:2], dtype=torch.float32).to(x.device)\n",
    "\n",
    "        encoder_output = self.bert_encoder(\n",
    "            hidden_states=x,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        pooled = self.pooler(encoder_output.last_hidden_state)  # (B, H)\n",
    "        logits = self.classifier(pooled)                        # (B, 1)\n",
    "        return torch.sigmoid(logits).squeeze(1)                 # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "686f48ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Discriminateur initialis√©.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "full_bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "netD = Discriminator(pretrained_encoder=full_bert, num_layers_to_keep=6).to(device)\n",
    "print(\"‚úÖ Discriminateur initialis√©.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1c724",
   "metadata": {},
   "source": [
    "Discriminateur est pr√™t √† √™tre entra√Æn√© ou √©valu√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ce149",
   "metadata": {},
   "source": [
    "## √âtape 7 ‚Äî Entra√Ænement du GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e041d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "nz = 100  # taille du vecteur latent\n",
    "lr = 2e-5\n",
    "beta1 = 0.5\n",
    "num_epochs = 5\n",
    "\n",
    "netG = Generator(input_dim=nz).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9553dd",
   "metadata": {},
   "source": [
    "### Boucle d'entra√Ænement :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f115ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96c4d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, seq_len=512, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        from transformers import BertConfig\n",
    "        from transformers.models.bert.modeling_bert import BertEncoder\n",
    "\n",
    "        config = BertConfig(\n",
    "            hidden_size=hidden_size,\n",
    "            num_hidden_layers=4,\n",
    "            num_attention_heads=12,\n",
    "            intermediate_size=3072\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, seq_len * hidden_size)\n",
    "        self.bert_encoder = BertEncoder(config)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.fc(noise)                             # (B, 512 * 768)\n",
    "        x = x.view(-1, self.seq_len, self.hidden_size) # (B, 512, 768)\n",
    "\n",
    "        attention_mask = torch.ones(x.size()[:2], dtype=torch.float32).to(x.device)\n",
    "        extended_mask = attention_mask[:, None, None, :]  # (B, 1, 1, S)\n",
    "\n",
    "        output = self.bert_encoder(\n",
    "            hidden_states=x,\n",
    "            attention_mask=extended_mask\n",
    "        )\n",
    "\n",
    "        return output.last_hidden_state  # (B, 512, 768)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224857b",
   "metadata": {},
   "source": [
    "### Validation jusqu'√† cette √©tape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f72f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test minimal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.models.bert.modeling_bert import BertEncoder\n",
    "from transformers import BertConfig\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, seq_len=512, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        config = BertConfig(\n",
    "            hidden_size=hidden_size,\n",
    "            num_hidden_layers=4,\n",
    "            num_attention_heads=12,\n",
    "            intermediate_size=3072\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, seq_len * hidden_size)\n",
    "        self.bert_encoder = BertEncoder(config)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        # G√©n√®re une s√©quence d'embeddings\n",
    "        x = self.fc(noise)                             # (B, seq_len * hidden)\n",
    "        x = x.view(-1, self.seq_len, self.hidden_size) # (B, seq_len, hidden)\n",
    "\n",
    "        # Cr√©e un masque d'attention plein\n",
    "        attention_mask = torch.ones(x.size()[:2], dtype=torch.float32).to(x.device)\n",
    "        extended_mask = attention_mask[:, None, None, :]  # (B, 1, 1, S)\n",
    "\n",
    "        output = self.bert_encoder(\n",
    "            hidden_states=x,\n",
    "            attention_mask=extended_mask\n",
    "        )\n",
    "\n",
    "        return output.last_hidden_state  # (B, seq_len, hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ G√©n√©rateur output shape : torch.Size([2, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test imm√©diat\n",
    "netG = Generator(input_dim=100).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(2, 100).to(device)\n",
    "    out = netG(noise)\n",
    "    print(\"‚úÖ G√©n√©rateur output shape :\", out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0eb069",
   "metadata": {},
   "source": [
    "Le g√©n√©rateur produit bien des embeddings BERT-like avec la forme attendue `(batch, seq_len, hidden_dim)` soit `(2, 512, 768)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558dacd8",
   "metadata": {},
   "source": [
    "## √âtape 8 ‚Äî Inf√©rence avec le Discriminateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26b9020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Textes √† inf√©rer : 3\n"
     ]
    }
   ],
   "source": [
    "# Charger les donn√©es de test\n",
    "test_df = pd.read_csv(\"data/test_essays.csv\")\n",
    "test_texts = test_df[\"text\"].tolist()\n",
    "test_ids = test_df[\"id\"].tolist()\n",
    "\n",
    "print(\"üì¶ Textes √† inf√©rer :\", len(test_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "088cb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "test_dataset = InferenceDataset(test_texts)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e18fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inf√©rence avec netD\n",
    "netD.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_texts in test_loader:\n",
    "        embeds = get_bert_embedding(batch_texts).to(device)\n",
    "        attention_mask = torch.ones(embeds.size()[:2], dtype=torch.float32).to(device)\n",
    "        extended_mask = attention_mask[:, None, None, :]\n",
    "\n",
    "        out = netD.bert_encoder(hidden_states=embeds, attention_mask=extended_mask)\n",
    "        pooled = netD.pooler(out.last_hidden_state)\n",
    "        logits = netD.classifier(pooled).squeeze(1)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        all_preds.extend(probs.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a075d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier 'submission.csv' g√©n√©r√©.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generated",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "766bc8ad-4fd4-4865-af9a-3005353af826",
       "rows": [
        [
         "0",
         "0000aaaa",
         "0.6067201"
        ],
        [
         "1",
         "1111bbbb",
         "0.5471869"
        ],
        [
         "2",
         "2222cccc",
         "0.5386636"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.606720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.547187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.538664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.606720\n",
       "1  1111bbbb   0.547187\n",
       "2  2222cccc   0.538664"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# G√©n√©rer le fichier de soumission\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"generated\": all_preds  # probabilit√©s entre 0 et 1\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ Fichier 'submission.csv' g√©n√©r√©.\")\n",
    "submission_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0eda4",
   "metadata": {},
   "source": [
    "Le fichier de soumission est bien g√©n√©r√© et conforme au format attendu. Voici le r√©capitulatif :\n",
    "\n",
    "---\n",
    "\n",
    "###  R√©sum√© de la soumission :\n",
    "\n",
    "* **Nom du fichier :** `submission.csv`\n",
    "* **Colonnes :** `id`, `generated`\n",
    "* **Nombre de lignes :** 3\n",
    "* **Extrait :**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f1117",
   "metadata": {},
   "source": [
    "## Bilan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbb856",
   "metadata": {},
   "source": [
    "###  √âtapes 1 √† 4 : Pr√©paration des donn√©es\n",
    "\n",
    "* **Chargement** des fichiers : `train_essays.csv`, `test_essays.csv`, `train_prompts.csv` ‚Üí OK.\n",
    "* Donn√©es propres : pas de valeurs manquantes.\n",
    "* Colonnes coh√©rentes : `text`, `prompt_id`, `generated`, etc.\n",
    "* Longueur des textes calcul√©e pour chaque exemple.\n",
    "\n",
    "---\n",
    "\n",
    "###  √âtapes 5 √† 6 : Mod√©lisation GAN\n",
    "\n",
    "* **G√©n√©rateur (netG)** : produit des embeddings de forme `(B, 9, 4096)` compatibles avec LLaMA.\n",
    "* **Discriminateur (netD)** : architecture adapt√©e, prend les embeddings et renvoie une proba.\n",
    "* **Entra√Ænement** : boucle GAN op√©rationnelle avec progression visible via `tqdm`.\n",
    "\n",
    "---\n",
    "\n",
    "###  √âtape 7 : Inf√©rence sur les textes tests\n",
    "\n",
    "* Embeddings extraits correctement pour 3 textes.\n",
    "* G√©n√©rateur + Discriminateur produisent des scores de probabilit√©.\n",
    "* **Fichier de soumission `submission.csv` g√©n√©r√©** au bon format.\n",
    "\n",
    "---\n",
    "\n",
    "###  √âtape 8 : √âvaluation AUC\n",
    "\n",
    "* Probl√®me initial : confusion entre embeddings BERT et LLaMA.\n",
    "* Corrig√© : passage aux bons embeddings LLaMA (4096 dims).\n",
    "* AUC affich√© : mais score encore **tr√®s faible** (`0.0000`) ‚Üí probablement √† cause :\n",
    "\n",
    "  * d‚Äôun d√©s√©quilibre des labels ;\n",
    "  * ou d‚Äôun mod√®le pas encore entra√Æn√© correctement.\n",
    "\n",
    "---\n",
    "\n",
    "###  Prochaine √©tape (9) :\n",
    "\n",
    "* Approfondir l‚Äô√©valuation :\n",
    "\n",
    "  * Sur jeux de donn√©es personnalis√©s.\n",
    "  * Visualisation des distributions.\n",
    "  * Test sur d'autres d√©tecteurs (GPT, RoBERTa...).\n",
    "  * Sauvegarde des mod√®les.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d495ac",
   "metadata": {},
   "source": [
    "## Applications potentielles innovantes et cr√©atives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb47044",
   "metadata": {},
   "source": [
    "### 1.  **D√©tecteur d‚Äôidentit√© stylom√©trique**\n",
    "\n",
    "**Objectif :** Utiliser les embeddings GAN pour **imiter** ou **d√©tecter** des styles d‚Äôauteurs sp√©cifiques (√©crivain, √©tudiant, auteur IA).\n",
    "\n",
    "**Concept :**\n",
    "\n",
    "* Entra√Æne le g√©n√©rateur √† imiter un style donn√© (ex. prompt + auteur humain).\n",
    "* Le discriminateur juge si le texte correspond au style vis√©.\n",
    "* Application : d√©tection de plagiat masqu√©, ou g√©n√©ration de textes dans un style cible.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.  **IA-Copilot pour examinateurs**\n",
    "\n",
    "**Objectif :** Cr√©er un outil interactif pour **aider les correcteurs** √† juger si un texte a √©t√© r√©dig√© par un humain ou une IA.\n",
    "\n",
    "**Fonctionnalit√©s :**\n",
    "\n",
    "* Surlignage des zones \"suspectes\".\n",
    "* Score de vraisemblance IA/humain.\n",
    "* Confiance calibr√©e sur diff√©rents mod√®les (GPT, Claude, LLaMA...).\n",
    "\n",
    "---\n",
    "\n",
    "### 3.  **Simulation d‚Äô√©volution du langage IA**\n",
    "\n",
    "**Objectif :** √âtudier comment les styles g√©n√©r√©s par IA √©voluent avec les mod√®les (GPT-2 ‚Üí GPT-4 ‚Üí Claude...).\n",
    "\n",
    "**M√©thode :**\n",
    "\n",
    "* G√©n√®re des jeux de textes avec diff√©rents mod√®les.\n",
    "* Entra√Æne un discriminateur chronologique.\n",
    "* Visualise l‚Äô√©volution de l'\"empreinte linguistique\" des IA.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.  **Text-to-Embedding Art**\n",
    "\n",
    "**Objectif :** Transformer les embeddings textuels en **visuels artistiques uniques** via un g√©n√©rateur conditionn√©.\n",
    "\n",
    "**Approche :**\n",
    "\n",
    "* Utiliser les embeddings comme latents.\n",
    "* G√©n√©rer des images \"abstraites\" repr√©sentant chaque texte.\n",
    "* Appliqu√© √† l‚Äôanalyse litt√©raire ou √† la po√©sie g√©n√©r√©e par IA.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.  **Tableau de bord de triche acad√©mique**\n",
    "\n",
    "**Objectif :** D√©ployer un syst√®me de scoring automatique pour les enseignants d√©tectant les r√©dactions suspectes.\n",
    "\n",
    "**Fonctionnalit√©s :**\n",
    "\n",
    "* Chargement de lots de devoirs.\n",
    "* Scoring IA/humain.\n",
    "* Visualisation des distributions par classe, par √©l√®ve, par type de prompt.\n",
    "* Alertes automatiques en cas de suspicion.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
